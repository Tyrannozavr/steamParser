# Сравнение архитектур: 1 воркер с 10 задачами vs 10 воркеров с 1 задачей

## Вариант 1: 1 воркер с 10 параллельными задачами (текущий подход)

### Как работает:
- **1 процесс** (контейнер) с **1 соединением** к RabbitMQ
- **10 корутин** (asyncio tasks) обрабатывают задачи **параллельно** в одном процессе
- **Semaphore** ограничивает количество одновременных задач до 10
- **RabbitMQ prefetch=10** - воркер получает до 10 неподтвержденных сообщений

### Преимущества:
1. **Эффективность ресурсов:**
   - Один процесс Python = меньше overhead на память
   - Одно соединение к RabbitMQ = меньше сетевых соединений
   - Общий пул соединений к БД и Redis

2. **Оптимально для I/O операций:**
   - Парсинг - это в основном сетевые запросы (HTTP)
   - Asyncio корутины идеально подходят для I/O-bound задач
   - Пока одна задача ждет ответа от API, другие выполняются

3. **Простота управления:**
   - Один контейнер легче мониторить
   - Проще логирование
   - Меньше точек отказа

4. **Retry механизм работает отлично:**
   - При ошибке в одной корутине, остальные продолжают работать
   - RabbitMQ обрабатывает retry независимо от количества корутин
   - Сообщение возвращается в очередь и может быть обработано любой корутиной

### Недостатки:
1. **Единая точка отказа:**
   - Если воркер упадет, все 10 задач остановятся
   - Но RabbitMQ сохранит неподтвержденные сообщения и перераспределит их

2. **Ограничение CPU:**
   - Если задачи CPU-intensive (редко для парсинга), может быть узкое место
   - Но парсинг - это I/O, так что не критично

3. **Ограничение памяти:**
   - Все 10 задач используют память одного процесса
   - Но для парсинга это обычно не проблема

---

## Вариант 2: 10 воркеров, каждый с 1 задачей

### Как работает:
- **10 процессов** (контейнеров), каждый с **1 соединением** к RabbitMQ
- Каждый воркер обрабатывает **1 задачу за раз**
- **RabbitMQ prefetch=1** для каждого воркера
- RabbitMQ автоматически распределяет задачи между воркерами

### Преимущества:
1. **Высокая отказоустойчивость:**
   - Если 1 воркер упадет, остальные 9 продолжают работать
   - Изоляция ошибок - ошибка в одном воркере не влияет на другие

2. **Простое масштабирование:**
   - Легко добавить/убрать воркеры
   - Можно запускать на разных серверах

3. **Изоляция ресурсов:**
   - Каждый воркер имеет свой процесс, память, CPU
   - Ошибка памяти в одном не влияет на другие

### Недостатки:
1. **Больше overhead:**
   - 10 процессов = больше потребление памяти (каждый процесс ~50-100MB)
   - 10 соединений к RabbitMQ = больше сетевых соединений
   - 10 соединений к БД = больше пулов соединений

2. **Меньше эффективность для I/O:**
   - Пока один воркер ждет ответа от API, он не может обработать другую задачу
   - В варианте 1: пока задача 1 ждет, задачи 2-10 работают
   - В варианте 2: пока воркер 1 ждет, он простаивает

3. **Сложнее управление:**
   - 10 контейнеров нужно мониторить
   - Больше логов для анализа
   - Сложнее отладка

4. **Retry механизм работает так же:**
   - Но при ошибке воркер может упасть, и задача вернется в очередь
   - Может быть задержка, пока RabbitMQ обнаружит, что воркер не отвечает

---

## Retry механизм - работает ли при текущем подходе?

### ✅ ДА, работает отлично!

### Как это работает:

1. **При ошибке в корутине:**
   ```python
   # В parsing_worker.py, task_handler:
   try:
       await task  # Ожидаем завершения корутины
       await message.ack()  # Подтверждаем только при успехе
   except Exception as task_error:
       raise  # Пробрасываем ошибку
   ```

2. **RabbitMQ обрабатывает ошибку:**
   ```python
   # В rabbitmq_service.py, consume_tasks:
   except Exception as callback_error:
       await self._handle_task_error(message, task_data, callback_error)
   ```

3. **Retry механизм:**
   - Увеличивает счетчик `x-retry-count`
   - Публикует сообщение в retry exchange с TTL (задержкой)
   - После TTL сообщение возвращается в основную очередь
   - **Любая свободная корутина** может взять задачу на повторную обработку

4. **Изоляция:**
   - Ошибка в одной корутине **НЕ влияет** на другие
   - Остальные 9 корутин продолжают работать
   - Retry задача обрабатывается независимо

### Пример работы:

```
Воркер 1 (10 корутин):
├─ Корутина 1: Задача 1 ✅ успешно
├─ Корутина 2: Задача 2 ❌ ошибка → retry через 60с
├─ Корутина 3: Задача 3 ✅ успешно
├─ Корутина 4: Задача 4 ✅ успешно
├─ Корутина 5: Задача 5 ✅ успешно
├─ ... (остальные работают)
└─ Через 60с: Корутина 2 (или любая свободная) обрабатывает retry задачи 2
```

---

## Рекомендация: **Вариант 1 (1 воркер с 10 задачами)**

### Почему:

1. **Парсинг - это I/O операция:**
   - Большую часть времени задачи ждут ответа от API
   - Asyncio корутины идеально подходят для этого
   - 1 воркер с 10 корутинами эффективнее, чем 10 воркеров с 1 задачей

2. **Retry механизм работает одинаково хорошо:**
   - При ошибке задача возвращается в очередь
   - Любая свободная корутина может взять retry задачу
   - Изоляция ошибок обеспечена на уровне корутин

3. **Меньше overhead:**
   - Меньше памяти, меньше соединений
   - Проще управление и мониторинг

4. **Масштабирование при необходимости:**
   - Если нужно больше параллелизма, можно:
     - Увеличить `MAX_CONCURRENT_TASKS` до 20-30
     - Или запустить 2-3 воркера с 10-15 задачами каждый

### Когда использовать Вариант 2 (10 воркеров):

1. **Если задачи CPU-intensive** (не наш случай)
2. **Если нужна максимальная изоляция** (критичные задачи)
3. **Если нужно распределить нагрузку** между серверами
4. **Если один воркер падает часто** (проблема в коде, нужно исправить)

---

## Текущая конфигурация - оптимальна!

**1 воркер × 10 задач = 10 параллельных задач**

- ✅ Эффективно для I/O операций
- ✅ Retry механизм работает отлично
- ✅ Изоляция ошибок на уровне корутин
- ✅ Минимальный overhead

### Если нужно больше параллелизма:

**Вариант A:** Увеличить задачи в одном воркере
```yaml
MAX_CONCURRENT_TASKS=20  # 1 воркер × 20 задач = 20 параллельных
```

**Вариант B:** Добавить еще один воркер
```bash
docker compose up -d --scale parsing-worker=2
# 2 воркера × 10 задач = 20 параллельных
```

**Вариант C:** Комбинированный (рекомендуется)
```yaml
MAX_CONCURRENT_TASKS=15
# + 2 воркера = 2 × 15 = 30 параллельных задач
```
