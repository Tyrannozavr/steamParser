"""
–ú–æ–¥—É–ª—å –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü.
–û—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü —Å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∑–∞–ø—Ä–æ—Å–æ–≤ –º–µ–∂–¥—É –ø—Ä–æ–∫—Å–∏.
"""
import asyncio
import httpx
from collections import deque
from typing import Dict, Any, List
from loguru import logger

from ..models import SearchFilters


async def parse_all_pages_parallel(
    parser,
    filters: SearchFilters,
    params: Dict[str, Any],
    items: List[Dict[str, Any]],
    total_count: int,
    current_start: int,
    max_per_request: int,
    active_proxies_count: int,
    max_retries: int,
    retry_delay: float,
    task_logger=None,
    total_pages: int = 0
):
    """
    –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü —Å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∑–∞–ø—Ä–æ—Å–æ–≤ –º–µ–∂–¥—É –ø—Ä–æ–∫—Å–∏.
    –ö–∞–∂–¥—ã–π –∑–∞–ø—Ä–æ—Å —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–π –ø—Ä–æ–∫—Å–∏ —á–µ—Ä–µ–∑ get_next_proxy.
    –ó–∞–¥–µ—Ä–∂–∫–∏ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–æ–∫—Å–∏ –æ—Ç–¥–µ–ª—å–Ω–æ.
    
    Args:
        parser: –≠–∫–∑–µ–º–ø–ª—è—Ä SteamMarketParser –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –µ–≥–æ –º–µ—Ç–æ–¥–æ–≤
        filters: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞
        params: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
        items: –¢–µ–∫—É—â–∏–π —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–º–µ—Ç–æ–≤
        total_count: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–º–µ—Ç–æ–≤
        current_start: –¢–µ–∫—É—â–∞—è –ø–æ–∑–∏—Ü–∏—è –Ω–∞—á–∞–ª–∞
        max_per_request: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–º–µ—Ç–æ–≤ –∑–∞ –∑–∞–ø—Ä–æ—Å
        active_proxies_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏
        max_retries: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫
        retry_delay: –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏
        task_logger: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –ª–æ–≥–≥–µ—Ä –¥–ª—è –∑–∞–¥–∞—á–∏
        total_pages: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü
    """
    # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –∑–∞–ø—Ä–æ—Å–∏—Ç—å
    pages_to_fetch = []
    start = current_start
    
    while start < total_count:
        remaining = total_count - start
        request_count = min(max_per_request, remaining)
        pages_to_fetch.append((start, request_count))
        start += request_count
    
    if not pages_to_fetch:
        logger.info("üìÑ –ù–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞")
        return
    
    logger.info(f"üìÑ –í—Å–µ–≥–æ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞: {len(pages_to_fetch)}")
    if task_logger and task_logger.task_id and total_pages > 0:
        task_logger.info(f"üìÑ –í—Å–µ–≥–æ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞: {total_pages}")
    
    # –°–æ–∑–¥–∞–µ–º —Å–µ–º–∞—Ñ–æ—Ä –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (–ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø—Ä–æ–∫—Å–∏)
    max_concurrent = min(active_proxies_count, len(pages_to_fetch)) if active_proxies_count > 0 else 1
    semaphore = asyncio.Semaphore(max_concurrent)
    logger.info(f"üîÑ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü: –º–∞–∫—Å–∏–º—É–º {max_concurrent} –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤")
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã (—É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫)
    results = [None] * len(pages_to_fetch)
    lock = asyncio.Lock()
    completed_pages = 0  # –°—á–µ—Ç—á–∏–∫ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
    
    async def fetch_page(page_idx: int, page_start: int, page_count: int):
        """–ó–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –æ–¥–Ω—É —Å—Ç—Ä–∞–Ω–∏—Ü—É —á–µ—Ä–µ–∑ –æ—Ç–¥–µ–ª—å–Ω—ã–π –ø—Ä–æ–∫—Å–∏."""
        nonlocal completed_pages
        
        async with semaphore:
            # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–π –ø—Ä–æ–∫—Å–∏ –¥–ª—è —ç—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
            page_proxy = None
            page_proxy_url = None
            if parser.proxy_manager:
                page_proxy = await parser.proxy_manager.get_next_proxy(force_refresh=False)
                if page_proxy:
                    page_proxy_url = page_proxy.url
                    logger.debug(f"   üåê –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_idx + 1}: –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–∫—Å–∏ ID={page_proxy.id}")
            
            # –ï—Å–ª–∏ –Ω–µ—Ç –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –ø—Ä–æ–∫—Å–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π
            if not page_proxy_url:
                page_proxy_url = parser.proxy
            
            # –°–æ–∑–¥–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–π HTTP –∫–ª–∏–µ–Ω—Ç –¥–ª—è —ç—Ç–æ–≥–æ –ø—Ä–æ–∫—Å–∏
            headers = parser._get_browser_headers()
            page_client = httpx.AsyncClient(
                proxy=page_proxy_url,
                timeout=parser.timeout,
                headers=headers,
                follow_redirects=True,
                cookies={}
            )
            
            try:
                # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                page_params = params.copy()
                page_params["start"] = page_start
                page_params["count"] = page_count
                
                page_success = False
                data_page = None
                
                for page_attempt in range(max_retries):
                    try:
                        # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º
                        page_headers = parser._get_browser_headers()
                        page_client.headers.update(page_headers)
                        
                        proxy_info = f" (—á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏: {page_proxy_url[:50]}...)" if page_proxy_url else " (–ø—Ä—è–º–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ)"
                        page_num = (page_start // max_per_request) + 1
                        logger.debug(f"üì° –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_idx + 1}: –ó–∞–ø—Ä–æ—Å –∫ Steam API (start={page_start}, count={page_count}){proxy_info}")
                        if task_logger and task_logger.task_id and total_pages > 0:
                            task_logger.info(f"üìÑ –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É {page_num} –∏–∑ {total_pages}")
                        
                        response_page = await page_client.get(parser.BASE_URL, params=page_params)
                        
                        logger.info(f"üì• –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_idx + 1}: –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç: status_code={response_page.status_code}")
                        
                        # –û–±—Ä–∞–±–æ—Ç–∫–∞ 429
                        if response_page.status_code == 429:
                            should_retry = await parser._handle_429_error(
                                response=response_page,
                                attempt=page_attempt,
                                max_retries=max_retries,
                                base_delay=retry_delay,
                                context=f"—Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_idx + 1} –¥–ª—è '{filters.item_name}'"
                            )
                            if should_retry:
                                continue
                            else:
                                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É {page_idx + 1} –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫.")
                                break
                        
                        response_page.raise_for_status()
                        data_page = response_page.json()
                        
                        if data_page.get("success"):
                            page_items = data_page.get("results", [])
                            if page_items:
                                async with lock:
                                    results[page_idx] = page_items
                                    completed_pages += 1
                                    current_completed = completed_pages
                                page_num = page_idx + 1
                                logger.info(f"‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}/{len(pages_to_fetch)}: –ü–æ–ª—É—á–µ–Ω–æ {len(page_items)} –ø—Ä–µ–¥–º–µ—Ç–æ–≤ (–ø—Ä–æ–≤–µ—Ä–µ–Ω–æ: {current_completed}/{len(pages_to_fetch)})")
                                if task_logger and task_logger.task_id and total_pages > 0:
                                    # –í—ã—á–∏—Å–ª—è–µ–º –Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
                                    actual_page = (page_start // max_per_request) + 1
                                    task_logger.info(f"‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {actual_page} –∏–∑ {total_pages}: –ü–æ–ª—É—á–µ–Ω–æ {len(page_items)} –ø—Ä–µ–¥–º–µ—Ç–æ–≤")
                                page_success = True
                                break
                            else:
                                logger.warning(f"‚ö†Ô∏è –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_idx + 1}: –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
                                break
                        else:
                            logger.warning(f"‚ö†Ô∏è –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_idx + 1}: API –≤–µ—Ä–Ω—É–ª –æ—à–∏–±–∫—É: {data_page.get('error', 'Unknown')}")
                            break
                            
                    except httpx.HTTPStatusError as e:
                        if e.response.status_code == 429:
                            should_retry = await parser._handle_429_error(
                                response=e.response,
                                attempt=page_attempt,
                                max_retries=max_retries,
                                base_delay=retry_delay,
                                context=f"—Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_idx + 1} –¥–ª—è '{filters.item_name}' (HTTPStatusError)"
                            )
                            if should_retry:
                                continue
                            else:
                                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É {page_idx + 1} –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫.")
                                break
                        else:
                            logger.error(f"‚ùå HTTP –æ—à–∏–±–∫–∞ {e.response.status_code} –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_idx + 1}: {e}")
                            break
                    except Exception as e:
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_idx + 1}: {e}")
                        break
                
                # –û—Ç–º–µ—á–∞–µ–º –ø—Ä–æ–∫—Å–∏ –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–π
                if page_proxy and parser.proxy_manager:
                    await parser.proxy_manager.mark_proxy_used(page_proxy, success=page_success)
                
            finally:
                await page_client.aclose()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
    tasks = [
        fetch_page(page_idx, page_start, page_count)
        for page_idx, (page_start, page_count) in enumerate(pages_to_fetch)
    ]
    
    await asyncio.gather(*tasks)
    
    # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
    for page_items in results:
        if page_items:
            items.extend(page_items)
    
    logger.info(f"üìä –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü –∑–∞–≤–µ—Ä—à–µ–Ω: –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ {completed_pages}/{len(pages_to_fetch)} —Å—Ç—Ä–∞–Ω–∏—Ü, –ø–æ–ª—É—á–µ–Ω–æ {len(items)} –∏–∑ {total_count} –ø—Ä–µ–¥–º–µ—Ç–æ–≤")

