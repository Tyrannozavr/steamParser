"""
–ú–æ–¥—É–ª—å –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü –ª–æ—Ç–æ–≤.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç Redis –æ—á–µ—Ä–µ–¥—å –¥–ª—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü –º–µ–∂–¥—É –≤–æ—Ä–∫–µ—Ä–∞–º–∏.
"""
import asyncio
import json
import random
from typing import Optional, List, Set
from datetime import datetime
from loguru import logger

from ..models import SearchFilters, ParsedItemData
from parsers import ItemPageParser, detect_item_type
from core.steam_market_parser.logger_utils import log_both
from core.steam_market_parser.page_range_optimizer import build_optimized_pages_list


async def parse_listings_parallel(
    parser,
    appid: int,
    hash_name: str,
    filters: SearchFilters,
    target_patterns: Optional[Set[int]],
    listings_per_page: int,
    total_count: int,
    active_proxies_count: int,
    task_logger=None,
    task=None,
    db_session=None,
    redis_service=None,
    db_manager=None
) -> List[ParsedItemData]:
    """
    –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü –ª–æ—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Redis –æ—á–µ—Ä–µ–¥–∏.
    –í–æ—Ä–∫–µ—Ä—ã –±–µ—Ä—É—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏–∑ –æ—á–µ—Ä–µ–¥–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ (—Å –ø–µ—Ä–≤–æ–π –ø–æ –ø–æ—Å–ª–µ–¥–Ω—é—é).
    
    Args:
        parser: –≠–∫–∑–µ–º–ø–ª—è—Ä SteamMarketParser
        appid: ID –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
        hash_name: –•—ç—à-–∏–º—è –ø—Ä–µ–¥–º–µ—Ç–∞
        filters: –§–∏–ª—å—Ç—Ä—ã –ø–æ–∏—Å–∫–∞
        target_patterns: –¶–µ–ª–µ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        listings_per_page: –õ–æ—Ç–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É (20)
        total_count: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–æ—Ç–æ–≤
        active_proxies_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏
        task_logger: –õ–æ–≥–≥–µ—Ä –∑–∞–¥–∞—á–∏
        task: –ó–∞–¥–∞—á–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        db_session: –°–µ—Å—Å–∏—è –ë–î
        redis_service: –°–µ—Ä–≤–∏—Å Redis
        
    Returns:
        –°–ø–∏—Å–æ–∫ ParsedItemData
    """
    def log(level: str, message: str):
        log_both(level, message, task_logger)
    
    log("info", f"üöÄ parse_listings_parallel: –ù–∞—á–∞–ª–æ (total_count={total_count}, active_proxies={active_proxies_count}, redis_service={redis_service is not None})")
    
    # –°–æ–∑–¥–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
    # –ï—Å–ª–∏ –µ—Å—Ç—å —Ñ–∏–ª—å—Ç—Ä –ø–æ —Ü–µ–Ω–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∏–Ω–∞—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    pages_to_fetch = await build_optimized_pages_list(
        parser=parser,
        appid=appid,
        hash_name=hash_name,
        filters=filters,
        total_count=total_count,
        listings_per_page=listings_per_page,
        log_func=log
    )
    
    if not pages_to_fetch:
        log("info", "üìÑ –ù–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü –ª–æ—Ç–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞")
        return []
    
    total_pages = len(pages_to_fetch)
    log("info", f"üìÑ –í—Å–µ–≥–æ —Å—Ç—Ä–∞–Ω–∏—Ü –ª–æ—Ç–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞: {total_pages} (–≤—Å–µ–≥–æ –ª–æ—Ç–æ–≤: {total_count})")
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏ –∏–∑ Redis –∫—ç—à–∞ (–±–µ–∑ –æ–±—Ä–∞—â–µ–Ω–∏—è –∫ –ë–î)
    if not parser.proxy_manager:
        log("error", "‚ùå ProxyManager –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
        return []
    
    # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–∫—Å–∏ –Ω–∞–ø—Ä—è–º—É—é –∏–∑ Redis –∫—ç—à–∞, –º–∏–Ω—É—è –ë–î
    available_proxies = []
    if parser.proxy_manager.redis_service:
        try:
            log("debug", "üîç –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–∫—Å–∏ –∏–∑ Redis –∫—ç—à–∞...")
            cached_proxies_data = await parser.proxy_manager.redis_service.get(parser.proxy_manager.REDIS_CACHE_KEY)
            if cached_proxies_data:
                import json as json_lib
                from datetime import datetime as dt
                from core import Proxy
                cached_proxies = json_lib.loads(cached_proxies_data)
                
                for p_data in cached_proxies:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–ª–æ–∫–∏—Ä–æ–≤–∫—É —á–µ—Ä–µ–∑ Redis
                    proxy_id = p_data["id"]
                    blocked_key = f"{parser.proxy_manager.REDIS_BLOCKED_PREFIX}{proxy_id}"
                    blocked_until = await parser.proxy_manager.redis_service.get(blocked_key)
                    
                    is_blocked = False
                    if blocked_until:
                        try:
                            blocked_until_dt = dt.fromisoformat(blocked_until)
                            if dt.now() < blocked_until_dt:
                                is_blocked = True
                        except:
                            pass
                    
                    if not is_blocked and p_data.get("is_active", True):
                        # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç Proxy –±–µ–∑ –ø—Ä–∏–≤—è–∑–∫–∏ –∫ —Å–µ—Å—Å–∏–∏
                        proxy = Proxy(
                            id=proxy_id,
                            url=p_data["url"],
                            is_active=p_data.get("is_active", True),
                            delay_seconds=p_data.get("delay_seconds", 0.2),
                            success_count=p_data.get("success_count", 0),
                            fail_count=p_data.get("fail_count", 0),
                            last_used=dt.fromisoformat(p_data["last_used"]) if p_data.get("last_used") else None,
                            last_error=p_data.get("last_error")
                        )
                        from sqlalchemy.orm import make_transient
                        make_transient(proxy)
                        available_proxies.append(proxy)
        except Exception as e:
            log("warning", f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø—Ä–æ–∫—Å–∏ –∏–∑ Redis: {e}")
    
    # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –∏–∑ Redis, –ø—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑ get_active_proxies (–Ω–æ –±–µ–∑ force_refresh)
    if not available_proxies:
        try:
            log("debug", "üîç –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–∫—Å–∏ —á–µ—Ä–µ–∑ get_active_proxies...")
            active_proxies = await parser.proxy_manager.get_active_proxies(force_refresh=False)
            if active_proxies:
                # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–æ–∫—Å–∏
                for proxy in active_proxies:
                    is_blocked = False
                    if parser.proxy_manager.redis_service:
                        try:
                            blocked_key = f"{parser.proxy_manager.REDIS_BLOCKED_PREFIX}{proxy.id}"
                            blocked_until = await parser.proxy_manager.redis_service.get(blocked_key)
                            if blocked_until:
                                from datetime import datetime as dt
                                try:
                                    blocked_until_dt = dt.fromisoformat(blocked_until)
                                    if dt.now() < blocked_until_dt:
                                        is_blocked = True
                                except:
                                    pass
                        except:
                            pass
                    
                    if not is_blocked:
                        available_proxies.append(proxy)
        except Exception as e:
            log("error", f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø—Ä–æ–∫—Å–∏: {e}")
    
    if not available_proxies:
        log("error", "‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏")
        return []
    
    log("info", f"üåê –î–æ—Å—Ç—É–ø–Ω–æ –ø—Ä–æ–∫—Å–∏: {len(available_proxies)}")
    
    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ n = proxies_count / 3 –∑–∞–ø—Ä–æ—Å–æ–≤
    max_concurrent = max(1, len(available_proxies) // 3)
    log("info", f"üîÑ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥: –º–∞–∫—Å–∏–º—É–º {max_concurrent} –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –≤–æ—Ä–∫–µ—Ä–æ–≤ (–∏–∑ {len(available_proxies)} –ø—Ä–æ–∫—Å–∏)")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ Redis –¥–ª—è –æ—á–µ—Ä–µ–¥–∏
    log("debug", f"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º Redis: redis_service={redis_service is not None}, is_connected={redis_service.is_connected() if redis_service else False}")
    if not redis_service:
        log("error", "‚ùå Redis –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –æ—á–µ—Ä–µ–¥–∏ —Å—Ç—Ä–∞–Ω–∏—Ü: redis_service is None")
        return []
    if not redis_service.is_connected():
        log("error", "‚ùå Redis –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –æ—á–µ—Ä–µ–¥–∏ —Å—Ç—Ä–∞–Ω–∏—Ü: redis_service –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω")
        try:
            await redis_service.connect()
            log("info", "‚úÖ Redis –ø–æ–¥–∫–ª—é—á–µ–Ω")
        except Exception as e:
            log("error", f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Redis: {e}")
            return []
    
    # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á –æ—á–µ—Ä–µ–¥–∏ –¥–ª—è —ç—Ç–æ–π –∑–∞–¥–∞—á–∏
    queue_key = f"parsing:pages:task_{task.id if task else 'unknown'}"
    log("info", f"üìã –°–æ–∑–¥–∞–µ–º Redis –æ—á–µ—Ä–µ–¥—å —Å—Ç—Ä–∞–Ω–∏—Ü: {queue_key}")
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤ Redis –æ—á–µ—Ä–µ–¥—å (–≤ –æ–±—Ä–∞—Ç–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ, —á—Ç–æ–±—ã –±—Ä–∞—Ç—å —Å –ø–µ—Ä–≤–æ–π)
    try:
        log("info", f"üì• –î–æ–±–∞–≤–ª—è–µ–º {len(pages_to_fetch)} —Å—Ç—Ä–∞–Ω–∏—Ü –≤ Redis –æ—á–µ—Ä–µ–¥—å...")
        page_data_list = []
        for page_num, page_start, page_count in pages_to_fetch:
            page_data = json.dumps({
                "page_num": page_num,
                "page_start": page_start,
                "page_count": page_count,
                "appid": appid,
                "hash_name": hash_name
            })
            page_data_list.append(page_data)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤ –æ—á–µ—Ä–µ–¥—å (LPUSH –¥–æ–±–∞–≤–ª—è–µ—Ç –≤ –Ω–∞—á–∞–ª–æ, –ø–æ—ç—Ç–æ–º—É –¥–æ–±–∞–≤–ª—è–µ–º –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ)
        await redis_service.lpush(queue_key, *reversed(page_data_list))
        queue_length = await redis_service.llen(queue_key)
        log("info", f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {len(pages_to_fetch)} —Å—Ç—Ä–∞–Ω–∏—Ü –≤ –æ—á–µ—Ä–µ–¥—å (–¥–ª–∏–Ω–∞ –æ—á–µ—Ä–µ–¥–∏: {queue_length})")
    except Exception as e:
        log("error", f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ —Å—Ç—Ä–∞–Ω–∏—Ü –≤ –æ—á–µ—Ä–µ–¥—å: {e}")
        import traceback
        log("error", f"   Traceback: {traceback.format_exc()}")
        return []
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã (—É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫)
    results = [None] * len(pages_to_fetch)
    matching_listings = []
    lock = asyncio.Lock()
    completed_pages = 0
    max_retries = 3  # –ú–∞–∫—Å–∏–º—É–º 3 –ø–æ–ø—ã—Ç–∫–∏ –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    
    # –°—á–µ—Ç—á–∏–∫–∏ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
    task_start_times = {}  # page_num -> start_time
    task_stages = {}  # page_num -> current_stage
    
    async def get_random_proxy() -> Optional:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–π –ø—Ä–æ–∫—Å–∏ –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö."""
        if not available_proxies:
            return None
        return random.choice(available_proxies)
    
    async def process_page_from_queue(worker_id: int):
        """–í–æ—Ä–∫–µ—Ä: –±–µ—Ä–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏–∑ Redis –æ—á–µ—Ä–µ–¥–∏ –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏—Ö."""
        nonlocal completed_pages, matching_listings
        
        log("info", f"    üë∑ –í–æ—Ä–∫–µ—Ä {worker_id}: –ó–∞–ø—É—â–µ–Ω, –æ–∂–∏–¥–∞–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏–∑ –æ—á–µ—Ä–µ–¥–∏...")
        pages_processed = 0
        
        while True:
            page_data_str = None
            page_data = None
            page_num = None
            page_start = None
            page_count = None
            
            try:
                # –ë–µ—Ä–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –∏–∑ –æ—á–µ—Ä–µ–¥–∏ (–±–ª–æ–∫–∏—Ä—É—é—â–∏–π pop —Å —Ç–∞–π–º–∞—É—Ç–æ–º 5 —Å–µ–∫—É–Ω–¥)
                log("debug", f"    üîç –í–æ—Ä–∫–µ—Ä {worker_id}: –û–∂–∏–¥–∞–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É –∏–∑ –æ—á–µ—Ä–µ–¥–∏ (—Ç–∞–π–º–∞—É—Ç 5—Å)...")
                page_data_str = await redis_service.rpop(queue_key, timeout=5.0)
                
                if not page_data_str:
                    # –û—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞, –ø—Ä–æ–≤–µ—Ä—è–µ–º –µ—â–µ —Ä–∞–∑
                    queue_length = await redis_service.llen(queue_key)
                    if queue_length == 0:
                        log("info", f"    ‚úÖ –í–æ—Ä–∫–µ—Ä {worker_id}: –û—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞, –∑–∞–≤–µ—Ä—à–∞–µ—Ç —Ä–∞–±–æ—Ç—É (–æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {pages_processed})")
                        break
                    else:
                        log("debug", f"    ‚è≥ –í–æ—Ä–∫–µ—Ä {worker_id}: –¢–∞–π–º–∞—É—Ç, –Ω–æ –≤ –æ—á–µ—Ä–µ–¥–∏ –µ—â–µ {queue_length} —Å—Ç—Ä–∞–Ω–∏—Ü, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º...")
                        continue
                
                # –ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                try:
                    page_data = json.loads(page_data_str)
                    page_num = page_data["page_num"]
                    page_start = page_data["page_start"]
                    page_count = page_data["page_count"]
                except Exception as e:
                    log("error", f"    ‚ùå –í–æ—Ä–∫–µ—Ä {worker_id}: –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –¥–∞–Ω–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {e}")
                    log("error", f"       –î–∞–Ω–Ω—ã–µ: {page_data_str[:100]}")
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∞–∫—Ç–∏–≤–Ω–∞ –ª–∏ –∑–∞–¥–∞—á–∞ (–¥–ª—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏)
                if task:
                    try:
                        from sqlalchemy import select
                        from core import MonitoringTask
                        if db_session:
                            result = await db_session.execute(
                                select(MonitoringTask).where(MonitoringTask.id == task.id)
                            )
                            db_task = result.scalar_one_or_none()
                            if db_task and not db_task.is_active:
                                log("info", f"üõë –í–æ—Ä–∫–µ—Ä {worker_id}: –ó–∞–¥–∞—á–∞ {task.id} –¥–µ–∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–∞, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}")
                                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –≤ –æ—á–µ—Ä–µ–¥—å –¥–ª—è –¥—Ä—É–≥–∏—Ö –≤–æ—Ä–∫–µ—Ä–æ–≤ (–µ—Å–ª–∏ –æ–Ω–∏ –µ—â–µ —Ä–∞–±–æ—Ç–∞—é—Ç)
                                # –ù–æ –ª—É—á—à–µ –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å —ç—Ç—É —Å—Ç—Ä–∞–Ω–∏—Ü—É
                                continue
                    except Exception as e:
                        log("warning", f"‚ö†Ô∏è –í–æ—Ä–∫–µ—Ä {worker_id}: –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–¥–∞—á–∏: {e}")
                
                # –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                task_start_time = datetime.now()
                task_start_times[page_num] = task_start_time
                task_stages[page_num] = "–Ω–∞—á–∞–ª–æ"
                pages_processed += 1
                
                log("info", f"    üìÑ –í–æ—Ä–∫–µ—Ä {worker_id}: –ù–∞—á–∞–ª –æ–±—Ä–∞–±–æ—Ç–∫—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}/{total_pages} (start={page_start}, count={page_count})")
                
                # Heartbeat –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∑–∞–≤–∏—Å—à–∏—Ö –≤–æ—Ä–∫–µ—Ä–æ–≤
                heartbeat_task = None
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º page_num –≤ –ª–æ–∫–∞–ª—å–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –¥–ª—è heartbeat
                current_page_num = page_num
                async def heartbeat():
                    while True:
                        await asyncio.sleep(30)  # –ö–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥
                        elapsed = (datetime.now() - task_start_time).total_seconds()
                        current_stage = task_stages.get(current_page_num, "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
                        log("warning", f"    üíì –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {current_page_num}: HEARTBEAT - –µ—â–µ —Ä–∞–±–æ—Ç–∞–µ—Ç (—ç—Ç–∞–ø: '{current_stage}', –ø—Ä–æ—à–ª–æ {elapsed:.1f}—Å)")
                
                try:
                    heartbeat_task = asyncio.create_task(heartbeat())
                except Exception as hb_error:
                    log("warning", f"    ‚ö†Ô∏è –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å heartbeat: {hb_error}")
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å retry
                for attempt in range(max_retries):
                    page_proxy = None
                    temp_client = None
                    temp_parser = None
                    
                    try:
                        # –≠—Ç–∞–ø 1: –í—ã–±–æ—Ä –ø—Ä–æ–∫—Å–∏
                        proxy_select_start = datetime.now()
                        task_stages[page_num] = f"–≤—ã–±–æ—Ä_–ø—Ä–æ–∫—Å–∏ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1})"
                        log("debug", f"    üîç –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–æ–∫—Å–∏ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})...")
                        
                        page_proxy = await get_random_proxy()
                        proxy_select_time = (datetime.now() - proxy_select_start).total_seconds()
                        
                        if not page_proxy:
                            log("warning", f"    ‚ö†Ô∏è –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})")
                            if attempt < max_retries - 1:
                                await asyncio.sleep(2.0)
                                continue
                            else:
                                log("error", f"    ‚ùå –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏ –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫")
                                async with lock:
                                    completed_pages += 1
                                break
                        
                        log("debug", f"    ‚úÖ –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –ü—Ä–æ–∫—Å–∏ ID={page_proxy.id} –≤—ã–±—Ä–∞–Ω –∑–∞ {proxy_select_time:.2f}—Å")
                        
                        # –≠—Ç–∞–ø 2: –°–æ–∑–¥–∞–Ω–∏–µ HTTP –∫–ª–∏–µ–Ω—Ç–∞
                        client_create_start = datetime.now()
                        task_stages[page_num] = f"—Å–æ–∑–¥–∞–Ω–∏–µ_–∫–ª–∏–µ–Ω—Ç–∞ (–ø—Ä–æ–∫—Å–∏ {page_proxy.id}, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1})"
                        log("debug", f"    üîß –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –°–æ–∑–¥–∞–µ–º HTTP –∫–ª–∏–µ–Ω—Ç —Å –ø—Ä–æ–∫—Å–∏ ID={page_proxy.id}...")
                        
                        from ..steam_http_client import SteamHttpClient
                        temp_client = SteamHttpClient(proxy=page_proxy.url, timeout=30, proxy_manager=parser.proxy_manager)
                        await temp_client._ensure_client()
                        
                        temp_parser = parser.__class__(proxy=page_proxy.url, timeout=30, redis_service=parser.redis_service, proxy_manager=parser.proxy_manager)
                        await temp_parser._ensure_client()
                        
                        client_create_time = (datetime.now() - client_create_start).total_seconds()
                        log("debug", f"    ‚úÖ –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: HTTP –∫–ª–∏–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω –∑–∞ {client_create_time:.2f}—Å")
                        
                        # –≠—Ç–∞–ø 3: –†–æ—Ç–∞—Ü–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
                        headers_start = datetime.now()
                        task_stages[page_num] = f"—Ä–æ—Ç–∞—Ü–∏—è_–∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ (–ø—Ä–æ–∫—Å–∏ {page_proxy.id}, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1})"
                        log("debug", f"    üîÑ –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏...")
                        page_headers = temp_parser._get_browser_headers()
                        temp_parser._client.headers.update(page_headers)
                        headers_time = (datetime.now() - headers_start).total_seconds()
                        log("debug", f"    ‚úÖ –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –ó–∞–≥–æ–ª–æ–≤–∫–∏ –æ–±–Ω–æ–≤–ª–µ–Ω—ã –∑–∞ {headers_time:.2f}—Å")
                        
                        # –≠—Ç–∞–ø 4: –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
                        request_start = datetime.now()
                        task_stages[page_num] = f"–≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ_–∑–∞–ø—Ä–æ—Å–∞ (–ø—Ä–æ–∫—Å–∏ {page_proxy.id}, start={page_start}, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1})"
                        log("info", f"    üì° –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏ ID={page_proxy.id} (start={page_start}, count={page_count})...")
                        
                        try:
                            render_data = await asyncio.wait_for(
                                temp_parser._fetch_render_api(appid, hash_name, start=page_start, count=page_count),
                                timeout=60.0
                            )
                            request_time = (datetime.now() - request_start).total_seconds()
                            log("info", f"    ‚úÖ –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –ó–∞–ø—Ä–æ—Å –≤—ã–ø–æ–ª–Ω–µ–Ω –∑–∞ {request_time:.2f}—Å")
                        except asyncio.TimeoutError:
                            request_time = (datetime.now() - request_start).total_seconds()
                            log("error", f"    ‚ùå –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –¢–ê–ô–ú–ê–£–¢ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ—Å–ª–µ {request_time:.2f}—Å –Ω–∞ —ç—Ç–∞–ø–µ '–≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ_–∑–∞–ø—Ä–æ—Å–∞'")
                            raise
                        except Exception as req_error:
                            request_time = (datetime.now() - request_start).total_seconds()
                            log("error", f"    ‚ùå –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –û–®–ò–ë–ö–ê –∑–∞–ø—Ä–æ—Å–∞ –ø–æ—Å–ª–µ {request_time:.2f}—Å: {type(req_error).__name__}: {req_error}")
                            raise
                        
                        if render_data is None:
                            log("warning", f"    ‚ö†Ô∏è –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –ü—Ä–æ–∫—Å–∏ ID={page_proxy.id} –Ω–µ –≤–µ—Ä–Ω—É–ª –¥–∞–Ω–Ω—ã–µ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})")
                            if attempt < max_retries - 1:
                                await asyncio.sleep(2.0)
                                continue
                            else:
                                log("error", f"    ‚ùå –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –ü—Ä–æ–∫—Å–∏ ID={page_proxy.id} –Ω–µ –≤–µ—Ä–Ω—É–ª –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫")
                                async with lock:
                                    completed_pages += 1
                                break
                        
                        # –≠—Ç–∞–ø 5: –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö
                        parse_start = datetime.now()
                        task_stages[page_num] = f"–ø–∞—Ä—Å–∏–Ω–≥_–¥–∞–Ω–Ω—ã—Ö (–ø—Ä–æ–∫—Å–∏ {page_proxy.id}, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1})"
                        log("info", f"    üîç –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö...")
                        
                        page_matching_listings = []
                        
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ assets
                        assets_data_map = {}
                        if 'assets' in render_data and '730' in render_data['assets']:
                            app_assets = render_data['assets']['730']
                            for contextid, items in app_assets.items():
                                for itemid, item in items.items():
                                    itemid = str(itemid)
                                    pattern = None
                                    float_value = None
                                    stickers = []
                                    
                                    # –ü–∞—Ä—Å–∏–º asset_properties –¥–ª—è –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –∏ float
                                    if 'asset_properties' in item:
                                        props = item['asset_properties']
                                        for prop in props:
                                            prop_id = prop.get('propertyid')
                                            # propertyid=1 –¥–ª—è —Å–∫–∏–Ω–æ–≤, propertyid=3 –¥–ª—è –±—Ä–µ–ª–∫–æ–≤
                                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±–∞, –Ω–æ –Ω–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º, –µ—Å–ª–∏ –ø–∞—Ç—Ç–µ—Ä–Ω —É–∂–µ –Ω–∞–π–¥–µ–Ω
                                            if (prop_id == 1 or prop_id == 3) and pattern is None:
                                                pattern = prop.get('int_value')
                                                try:
                                                    pattern = int(pattern) if pattern is not None else None
                                                except (ValueError, TypeError):
                                                    pattern = None
                                            elif prop_id == 2:
                                                float_value_raw = prop.get('float_value')
                                                try:
                                                    float_value = float(float_value_raw) if float_value_raw is not None else None
                                                except (ValueError, TypeError):
                                                    float_value = None
                                    
                                    # –ü–∞—Ä—Å–∏–º descriptions –¥–ª—è –Ω–∞–∫–ª–µ–µ–∫ –∏—Å–ø–æ–ª—å–∑—É—è StickerParser
                                    if 'descriptions' in item:
                                        from core.utils.sticker_parser import StickerParser
                                        parsed_stickers = StickerParser.parse_stickers_from_asset(item, max_stickers=5)
                                        stickers.extend(parsed_stickers)
                                    
                                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
                                    if pattern is not None or float_value is not None or stickers:
                                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ itemid (—ç—Ç–æ ID –∏–∑ assets)
                                        assets_data_map[itemid] = {
                                            'pattern': pattern,
                                            'float_value': float_value,
                                            'stickers': stickers,
                                            'contextid': contextid,
                                            'itemid': itemid  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                                        }
                                        if stickers:
                                            log("debug", f"    üíæ –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã –Ω–∞–∫–ª–µ–π–∫–∏ –¥–ª—è itemid={itemid}: {[s.name for s in stickers[:3]]}")
                        
                        # –ü–∞—Ä—Å–∏–º HTML –∏–∑ results_html
                        results_html = render_data.get('results_html', '')
                        if not results_html:
                            log("warning", f"    ‚ö†Ô∏è –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: results_html –ø—É—Å—Ç (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})")
                            if attempt < max_retries - 1:
                                await asyncio.sleep(2.0)
                                continue
                            else:
                                log("error", f"    ‚ùå –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: results_html –ø—É—Å—Ç –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫")
                                async with lock:
                                    completed_pages += 1
                                break
                        
                        parser_obj = ItemPageParser(results_html)
                        page_listings = parser_obj.get_all_listings()
                        
                        # –°–≤—è–∑—ã–≤–∞–µ–º listing_id —Å –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ assets —á–µ—Ä–µ–∑ listinginfo
                        if 'listinginfo' in render_data:
                            listinginfo = render_data['listinginfo']
                            for listing in page_listings:
                                listing_id = listing.get('listing_id')
                                if listing_id:
                                    listing_id = str(listing_id)
                                else:
                                    continue
                                
                                if listing_id in listinginfo:
                                    listing_data = listinginfo[listing_id]
                                    if 'asset' in listing_data:
                                        asset_info = listing_data['asset']
                                        asset_id = asset_info.get('id')
                                        asset_contextid = asset_info.get('contextid')
                                        if asset_id:
                                            asset_id = str(asset_id)
                                        
                                        # –ò—â–µ–º –¥–∞–Ω–Ω—ã–µ –≤ assets_data_map
                                        found_asset_data = None
                                        if asset_id in assets_data_map:
                                            found_asset_data = assets_data_map[asset_id]
                                            log("debug", f"    ‚úÖ –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –ù–∞–π–¥–µ–Ω asset –ø–æ asset_id={asset_id}")
                                        elif listing_id in assets_data_map:
                                            found_asset_data = assets_data_map[listing_id]
                                            log("debug", f"    ‚úÖ –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –ù–∞–π–¥–µ–Ω asset –ø–æ listing_id={listing_id}")
                                        else:
                                            # Fallback: –∏—â–µ–º –ø–æ itemid –∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –≤ assets_data_map –∑–∞–ø–∏—Å—å —Å —Ç–∞–∫–∏–º itemid
                                            for key, data in assets_data_map.items():
                                                if data.get('itemid') == asset_id:
                                                    found_asset_data = data
                                                    log("info", f"    ‚úÖ –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –ù–∞–π–¥–µ–Ω asset –ø–æ itemid={asset_id} (–∫–ª—é—á –≤ map: {key})")
                                                    break
                                            
                                            if not found_asset_data:
                                                # Fallback 1: –∏—â–µ–º –ø–æ –≤—Å–µ–º –∫–ª—é—á–∞–º, —Å—Ä–∞–≤–Ω–∏–≤–∞—è itemid
                                                for key, data in assets_data_map.items():
                                                    stored_itemid = data.get('itemid')
                                                    if stored_itemid and str(stored_itemid) == str(asset_id):
                                                        found_asset_data = data
                                                        log("info", f"    ‚úÖ –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –ù–∞–π–¥–µ–Ω asset –ø–æ itemid={asset_id} (–∫–ª—é—á –≤ map: {key})")
                                                        break
                                                
                                                if not found_asset_data:
                                                    # Fallback 2: –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π asset —Å –Ω–∞–∫–ª–µ–π–∫–∞–º–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
                                                    assets_with_stickers = {k: v for k, v in assets_data_map.items() if v.get('stickers')}
                                                    if len(assets_with_stickers) == 1:
                                                        found_asset_data = list(assets_with_stickers.values())[0]
                                                        log("info", f"    ‚ö†Ô∏è –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω fallback (–µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π asset —Å –Ω–∞–∫–ª–µ–π–∫–∞–º–∏) –¥–ª—è listing_id={listing_id}, asset_id={asset_id}")
                                                    elif len(assets_with_stickers) > 1:
                                                        # –ï—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ assets —Å –Ω–∞–∫–ª–µ–π–∫–∞–º–∏, –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
                                                        # –ò—â–µ–º asset —Å —Ç–∞–∫–∏–º –∂–µ contextid
                                                        if 'asset_contextid' in locals() and asset_contextid:
                                                            matching_by_context = [v for k, v in assets_with_stickers.items() if v.get('contextid') == asset_contextid]
                                                            if len(matching_by_context) == 1:
                                                                found_asset_data = matching_by_context[0]
                                                                log("info", f"    ‚úÖ –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –ù–∞–π–¥–µ–Ω asset –ø–æ contextid={asset_contextid} –¥–ª—è listing_id={listing_id}")
                                                        else:
                                                            log("warning", f"    ‚ö†Ô∏è –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –ù–ï –ù–ê–ô–î–ï–ù asset –¥–ª—è listing_id={listing_id}, asset_id={asset_id}")
                                                            log("warning", f"       assets_data_map —Å–æ–¥–µ—Ä–∂–∏—Ç {len(assets_data_map)} –∑–∞–ø–∏—Å–µ–π")
                                                            log("warning", f"       assets_with_stickers: {len(assets_with_stickers)} –∑–∞–ø–∏—Å–µ–π")
                                                            if assets_data_map:
                                                                log("warning", f"       –ü—Ä–∏–º–µ—Ä—ã –∫–ª—é—á–µ–π –≤ assets_data_map: {list(assets_data_map.keys())[:5]}")
                                                                sample_itemids = [v.get('itemid') for v in list(assets_data_map.values())[:5] if v.get('itemid')]
                                                                if sample_itemids:
                                                                    log("warning", f"       –ü—Ä–∏–º–µ—Ä—ã itemid –≤ –¥–∞–Ω–Ω—ã—Ö: {sample_itemids}")
                                                    else:
                                                        log("warning", f"    ‚ö†Ô∏è –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –ù–ï –ù–ê–ô–î–ï–ù asset –¥–ª—è listing_id={listing_id}, asset_id={asset_id}")
                                                        log("warning", f"       assets_data_map —Å–æ–¥–µ—Ä–∂–∏—Ç {len(assets_data_map)} –∑–∞–ø–∏—Å–µ–π")
                                                        log("warning", f"       assets_with_stickers: {len(assets_with_stickers)} –∑–∞–ø–∏—Å–µ–π")
                                                        if assets_data_map:
                                                            log("warning", f"       –ü—Ä–∏–º–µ—Ä—ã –∫–ª—é—á–µ–π –≤ assets_data_map: {list(assets_data_map.keys())[:5]}")
                                                            sample_itemids = [v.get('itemid') for v in list(assets_data_map.values())[:5] if v.get('itemid')]
                                                            if sample_itemids:
                                                                log("warning", f"       –ü—Ä–∏–º–µ—Ä—ã itemid –≤ –¥–∞–Ω–Ω—ã—Ö: {sample_itemids}")
                                        
                                        if found_asset_data:
                                            stickers_count = len(found_asset_data.get('stickers', []))
                                            listing['pattern'] = found_asset_data.get('pattern')
                                            listing['float_value'] = found_asset_data.get('float_value')
                                            listing['stickers'] = found_asset_data.get('stickers', [])
                                            log("debug", f"    ‚úÖ –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –°–≤—è–∑–∞–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è listing_id={listing_id}: –Ω–∞–∫–ª–µ–µ–∫={stickers_count}, pattern={found_asset_data.get('pattern')}, float={found_asset_data.get('float_value')}")
                                        else:
                                            log("warning", f"    ‚ö†Ô∏è –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –ù–ï –°–í–Ø–ó–ê–ù–´ –¥–∞–Ω–Ω—ã–µ –¥–ª—è listing_id={listing_id}, asset_id={asset_id} - –Ω–∞–∫–ª–µ–π–∫–∏ –±—É–¥—É—Ç –ø—É—Å—Ç—ã–º–∏")
                        
                        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –ª–æ—Ç –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
                        for listing in page_listings:
                            listing_price = listing.get('price', 0.0)
                            listing_id = listing.get('listing_id')
                            listing_pattern = listing.get('pattern')
                            listing_float = listing.get('float_value')
                            stickers = listing.get('stickers', [])
                            inspect_link = listing.get('inspect_link')
                            
                            # –°–æ–∑–¥–∞–µ–º ParsedItemData
                            item_type = detect_item_type(
                                hash_name or "",
                                listing_float is not None,
                                len(stickers) > 0
                            )
                            if listing_pattern is not None and listing_pattern > 999:
                                item_type = "keychain"
                            
                            is_stattrak = "StatTrak" in hash_name or "StatTrak‚Ñ¢" in hash_name
                            
                            parsed_data = ParsedItemData(
                                float_value=listing_float,
                                pattern=listing_pattern,
                                stickers=stickers,
                                total_stickers_price=0.0,
                                item_name=hash_name,
                                item_price=listing_price,
                                inspect_links=[inspect_link] if inspect_link else [],
                                item_type=item_type,
                                is_stattrak=is_stattrak,
                                listing_id=listing_id
                            )
                            
                            # –†–ê–ù–ù–Ø–Ø –ü–†–û–í–ï–†–ö–ê –ü–ê–¢–¢–ï–†–ù–ê: –µ—Å–ª–∏ –ø–∞—Ç—Ç–µ—Ä–Ω –∏–∑–≤–µ—Å—Ç–µ–Ω –∏ –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ä–∞–∑—É
                            # –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –ø—Ä–µ–¥–º–µ—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ —Ç–æ—á–Ω–æ –Ω–µ –ø—Ä–æ–π–¥—É—Ç —Ñ–∏–ª—å—Ç—Ä—ã
                            if listing_pattern is not None and filters.pattern_list:
                                target_patterns = filters.pattern_list.patterns if filters.pattern_list else []
                                if target_patterns:
                                    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω (–¥–ª—è keychain –±–µ—Ä–µ–º –æ—Å—Ç–∞—Ç–æ–∫ –æ—Ç –¥–µ–ª–µ–Ω–∏—è –Ω–∞ 1000)
                                    normalized_pattern = listing_pattern % 1000 if listing_pattern > 999 else listing_pattern
                                    if normalized_pattern not in target_patterns:
                                        log("debug", f"    ‚è≠Ô∏è –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–µ–¥–º–µ—Ç —Å –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º {listing_pattern} (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω: {normalized_pattern}), –Ω–µ –≤ —Å–ø–∏—Å–∫–µ {target_patterns}")
                                        continue
                            
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î
                            item_dict = {
                                "sell_price_text": f"${listing_price:.2f}",
                                "asset_description": {"market_hash_name": hash_name},
                                "name": hash_name
                            }
                            matches = await parser.filter_service.matches_filters(item_dict, filters, parsed_data)
                            if matches:
                                # –í–ê–ñ–ù–û: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –°–†–ê–ó–£ –ø–æ—Å–ª–µ –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è, –∞ –Ω–µ –ø–æ—Å–ª–µ –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
                                # –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ—Ç–ø—Ä–∞–≤–ª—è—é—Ç—Å—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ
                                if task and db_manager:
                                    log("info", f"    üîÑ –í–æ—Ä–∫–µ—Ä {worker_id}: –ù–∞–π–¥–µ–Ω –ø–æ–¥—Ö–æ–¥—è—â–∏–π –ø—Ä–µ–¥–º–µ—Ç, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –°–†–ê–ó–£ (task={task.id}, db_manager={db_manager is not None})")
                                    try:
                                        # –°–æ–∑–¥–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—É—é —Å–µ—Å—Å–∏—é –ë–î –¥–ª—è —ç—Ç–æ–≥–æ –≤–æ—Ä–∫–µ—Ä–∞
                                        worker_db_session = await db_manager.get_session()
                                        try:
                                            from .process_results import process_item_result
                                            
                                            log("info", f"    üìù –í–æ—Ä–∫–µ—Ä {worker_id}: –í—ã–∑—ã–≤–∞–µ–º process_item_result –¥–ª—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏...")
                                            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ä–∞–∑—É (—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –ë–î + –æ—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è)
                                            saved = await process_item_result(
                                                parser=parser,
                                                task=task,
                                                parsed_data=parsed_data,
                                                filters=filters,
                                                db_session=worker_db_session,
                                                redis_service=redis_service,
                                                task_logger=task_logger
                                            )
                                            
                                            if saved:
                                                log("info", f"    ‚îÇ ‚úÖ‚úÖ‚úÖ –í–°–ï –§–ò–õ–¨–¢–†–´ –ü–†–û–ô–î–ï–ù–´ –ò –ü–†–ï–î–ú–ï–¢ –°–û–•–†–ê–ù–ï–ù –°–†–ê–ó–£!")
                                                log("info", f"    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
                                                # –í–ê–ñ–ù–û: –ù–ï –¥–æ–±–∞–≤–ª—è–µ–º –≤ page_matching_listings, –µ—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω
                                                # –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç –ø–æ–≤—Ç–æ—Ä–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É —á–µ—Ä–µ–∑ ResultsProcessorService
                                                # –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ process_item_result
                                                log("info", f"    ‚ÑπÔ∏è –ü—Ä–µ–¥–º–µ—Ç —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ, –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                                            else:
                                                log("info", f"    ‚îÇ ‚ùå –ù–ï –ü–†–û–®–ï–õ –§–ò–õ–¨–¢–†–´ –ò–õ–ò –£–ñ–ï –°–£–©–ï–°–¢–í–£–ï–¢ –í –ë–î")
                                                log("info", f"    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
                                        finally:
                                            # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–µ—Å—Å–∏—é –≤–æ—Ä–∫–µ—Ä–∞
                                            await worker_db_session.close()
                                    except Exception as process_error:
                                        error_msg = str(process_error)[:200]
                                        log("error", f"    ‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {type(process_error).__name__}: {error_msg}")
                                        import traceback
                                        log("error", f"    Traceback: {traceback.format_exc()}")
                                        # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤—Å–µ —Ä–∞–≤–Ω–æ –¥–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                                        page_matching_listings.append(parsed_data)
                                else:
                                    # –ï—Å–ª–∏ –Ω–µ—Ç task –∏–ª–∏ db_manager, –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫ (—Å—Ç–∞—Ä–∞—è –ª–æ–≥–∏–∫–∞)
                                    log("warning", f"    ‚ö†Ô∏è –í–æ—Ä–∫–µ—Ä {worker_id}: –ù–µ—Ç task –∏–ª–∏ db_manager (task={task is not None}, db_manager={db_manager is not None}), –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—É—é –ª–æ–≥–∏–∫—É")
                                    page_matching_listings.append(parsed_data)
                        
                        parse_time = (datetime.now() - parse_start).total_seconds()
                        log("debug", f"    ‚úÖ –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {parse_time:.2f}—Å, –Ω–∞–π–¥–µ–Ω–æ {len(page_matching_listings)} –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –∏–∑ {len(page_listings)} –ª–æ—Ç–æ–≤")
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                        save_start = datetime.now()
                        task_stages[page_num] = "—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ_—Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"
                        async with lock:
                            # –ù–∞—Ö–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å —Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Å–ø–∏—Å–∫–µ
                            page_idx = page_num - 1
                            if 0 <= page_idx < len(results):
                                results[page_idx] = page_matching_listings
                            completed_pages += 1
                            total_time = (datetime.now() - task_start_time).total_seconds()
                            log("info", f"    ‚úÖ –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}/{total_pages} –∑–∞–≤–µ—Ä—à–µ–Ω–∞: –ù–∞–π–¥–µ–Ω–æ {len(page_listings)} –ª–æ—Ç–æ–≤, –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö {len(page_matching_listings)} (–∑–∞–≤–µ—Ä—à–µ–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {completed_pages}/{len(pages_to_fetch)}, –≤—Ä–µ–º—è: {total_time:.2f}—Å)")
                        
                        save_time = (datetime.now() - save_start).total_seconds()
                        log("debug", f"    ‚úÖ –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –∑–∞ {save_time:.2f}—Å")
                        
                        # –û—Ç–º–µ—á–∞–µ–º –ø—Ä–æ–∫—Å–∏ –∫–∞–∫ —É—Å–ø–µ—à–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–π
                        proxy_mark_start = datetime.now()
                        if parser.proxy_manager and page_proxy:
                            await parser.proxy_manager.mark_proxy_used(page_proxy, success=True)
                        proxy_mark_time = (datetime.now() - proxy_mark_start).total_seconds()
                        log("debug", f"    ‚úÖ –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –ü—Ä–æ–∫—Å–∏ ID={page_proxy.id} –æ—Ç–º–µ—á–µ–Ω –∫–∞–∫ —É—Å–ø–µ—à–Ω—ã–π –∑–∞ {proxy_mark_time:.2f}—Å")
                        
                        # –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–ª–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—É, –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞ retry
                        task_stages[page_num] = "–∑–∞–≤–µ—Ä—à–µ–Ω–æ"
                        if page_num in task_start_times:
                            del task_start_times[page_num]
                        if page_num in task_stages:
                            del task_stages[page_num]
                        break
                        
                    except asyncio.TimeoutError:
                        if heartbeat_task:
                            heartbeat_task.cancel()
                            try:
                                await heartbeat_task
                            except asyncio.CancelledError:
                                pass
                        timeout_time = (datetime.now() - task_start_time).total_seconds()
                        current_stage = task_stages.get(page_num, "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
                        log("error", f"    ‚è±Ô∏è –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –¢–ê–ô–ú–ê–£–¢ –∑–∞–ø—Ä–æ—Å–∞ (60—Å) –Ω–∞ —ç—Ç–∞–ø–µ '{current_stage}' –ø–æ—Å–ª–µ {timeout_time:.2f}—Å —Ä–∞–±–æ—Ç—ã (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})")
                        
                        if attempt < max_retries - 1:
                            log("warning", f"    ‚ö†Ô∏è –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞, –ø–æ–≤—Ç–æ—Ä—è–µ–º —Å –¥—Ä—É–≥–∏–º –ø—Ä–æ–∫—Å–∏...")
                            if page_proxy and parser.proxy_manager:
                                await parser.proxy_manager.mark_proxy_used(page_proxy, success=False, error="Timeout")
                            await asyncio.sleep(2.0)
                            continue
                        else:
                            log("error", f"    ‚ùå –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫, –æ–±—â–µ–µ –≤—Ä–µ–º—è: {timeout_time:.2f}—Å")
                            log("error", f"    üìã –î–ï–¢–ê–õ–ò –û–®–ò–ë–ö–ò: –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}, —ç—Ç–∞–ø: {current_stage}, –ø—Ä–æ–∫—Å–∏: {page_proxy.id if page_proxy else 'None'}, –≤—Ä–µ–º—è: {timeout_time:.2f}—Å")
                            if page_proxy and parser.proxy_manager:
                                await parser.proxy_manager.mark_proxy_used(page_proxy, success=False, error="Timeout")
                            async with lock:
                                completed_pages += 1
                            if page_num in task_start_times:
                                del task_start_times[page_num]
                            if page_num in task_stages:
                                del task_stages[page_num]
                            break
                    except Exception as e:
                        if heartbeat_task:
                            heartbeat_task.cancel()
                            try:
                                await heartbeat_task
                            except asyncio.CancelledError:
                                pass
                        error_msg = str(e)[:200]
                        current_stage = task_stages.get(page_num, "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
                        error_time = (datetime.now() - task_start_time).total_seconds()
                        log("error", f"    ‚ùå –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –û–®–ò–ë–ö–ê –Ω–∞ —ç—Ç–∞–ø–µ '{current_stage}' –ø–æ—Å–ª–µ {error_time:.2f}—Å: {type(e).__name__}: {error_msg} (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})")
                        import traceback
                        log("error", f"    üìã Traceback: {traceback.format_exc()[:500]}")
                        
                        if attempt < max_retries - 1:
                            log("warning", f"    ‚ö†Ô∏è –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –û—à–∏–±–∫–∞, –ø–æ–≤—Ç–æ—Ä—è–µ–º —Å –¥—Ä—É–≥–∏–º –ø—Ä–æ–∫—Å–∏...")
                            if page_proxy and parser.proxy_manager:
                                is_429 = "429" in error_msg or "Too Many Requests" in error_msg
                                await parser.proxy_manager.mark_proxy_used(page_proxy, success=False, error=error_msg, is_429_error=is_429)
                            await asyncio.sleep(2.0)
                            continue
                        else:
                            log("error", f"    ‚ùå –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –û—à–∏–±–∫–∞ –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫: {type(e).__name__}: {error_msg}")
                            log("error", f"    üìã –î–ï–¢–ê–õ–ò –û–®–ò–ë–ö–ò: –í–æ—Ä–∫–µ—Ä {worker_id}, —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}, —ç—Ç–∞–ø: {current_stage}, –ø—Ä–æ–∫—Å–∏: {page_proxy.id if page_proxy else 'None'}, –æ—à–∏–±–∫–∞: {error_msg}")
                            if page_proxy and parser.proxy_manager:
                                is_429 = "429" in error_msg or "Too Many Requests" in error_msg
                                await parser.proxy_manager.mark_proxy_used(page_proxy, success=False, error=error_msg, is_429_error=is_429)
                            async with lock:
                                completed_pages += 1
                            if page_num in task_start_times:
                                del task_start_times[page_num]
                            if page_num in task_stages:
                                del task_stages[page_num]
                            break
                    finally:
                        # –ó–∞–∫—Ä—ã–≤–∞–µ–º –∫–ª–∏–µ–Ω—Ç—ã
                        if temp_parser:
                            try:
                                await temp_parser.close()
                            except:
                                pass
                        if temp_client:
                            try:
                                await temp_client.close()
                            except:
                                pass
                
            except Exception as e:
                error_msg = str(e)[:200]
                log("error", f"    ‚ùå –í–æ—Ä–∫–µ—Ä {worker_id}: –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {type(e).__name__}: {error_msg}")
                import traceback
                log("error", f"    üìã Traceback: {traceback.format_exc()}")
                if page_num:
                    async with lock:
                        completed_pages += 1
                    if page_num in task_start_times:
                        del task_start_times[page_num]
                    if page_num in task_stages:
                        del task_stages[page_num]
        
        log("info", f"    üèÅ –í–æ—Ä–∫–µ—Ä {worker_id}: –ó–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É (–æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {pages_processed})")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –≤–æ—Ä–∫–µ—Ä—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
    log("info", f"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º {max_concurrent} –≤–æ—Ä–∫–µ—Ä–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü –∏–∑ Redis –æ—á–µ—Ä–µ–¥–∏...")
    
    workers = [
        asyncio.create_task(process_page_from_queue(worker_id))
        for worker_id in range(1, max_concurrent + 1)
    ]
    
    # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –≤–æ—Ä–∫–µ—Ä–æ–≤
    try:
        await asyncio.gather(*workers, return_exceptions=True)
    except Exception as e:
        log("error", f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –≤–æ—Ä–∫–µ—Ä–æ–≤: {e}")
        import traceback
        log("error", f"   Traceback: {traceback.format_exc()}")
    
    # –û—á–∏—â–∞–µ–º –æ—á–µ—Ä–µ–¥—å –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
    try:
        await redis_service.delete(queue_key)
        log("info", f"üóëÔ∏è –û—á–µ—Ä–µ–¥—å {queue_key} –æ—á–∏—â–µ–Ω–∞")
    except Exception as e:
        log("warning", f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—á–∏—Å—Ç–∏—Ç—å –æ—á–µ—Ä–µ–¥—å {queue_key}: {e}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≤–∏—Å—à–∏–µ –∑–∞–¥–∞—á–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
    if task_start_times:
        now = datetime.now()
        hung_pages = []
        for page_num, start_time in task_start_times.items():
            elapsed = (now - start_time).total_seconds()
            if elapsed > 300:  # 5 –º–∏–Ω—É—Ç
                current_stage = task_stages.get(page_num, "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
                hung_pages.append((page_num, elapsed, current_stage))
        
        if hung_pages:
            log("error", f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∑–∞–≤–∏—Å—à–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã:")
            for page_num, elapsed, stage in hung_pages:
                log("error", f"   üìã –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –∑–∞–≤–∏—Å–ª–∞ –Ω–∞ —ç—Ç–∞–ø–µ '{stage}' —É–∂–µ {elapsed:.1f}—Å")
    
    # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
    # –í–ê–ñ–ù–û: –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–º –ø–∞—Ä—Å–µ—Ä–µ (—Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è),
    # —Ç–æ page_matching_listings –±—É–¥–µ—Ç –ø—É—Å—Ç—ã–º, –∏ –º—ã –Ω–µ –≤–µ—Ä–Ω–µ–º –∏—Ö –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
    for page_matching_listings in results:
        if page_matching_listings:
            matching_listings.extend(page_matching_listings)
    
    log("info", f"üìä –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω: –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ {completed_pages}/{len(pages_to_fetch)} —Å—Ç—Ä–∞–Ω–∏—Ü, –Ω–∞–π–¥–µ–Ω–æ {len(matching_listings)} –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –ª–æ—Ç–æ–≤")
    if len(matching_listings) == 0:
        log("info", f"‚ÑπÔ∏è –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—É—Å—Ç - –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥–º–µ—Ç—ã —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã —Å—Ä–∞–∑—É (—É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã)")
    
    return matching_listings
