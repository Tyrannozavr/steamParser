#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞: –æ—Ç –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ –¥–æ –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è.
–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—Ä–µ–º—è –∫–∞–∂–¥–æ–≥–æ —ç—Ç–∞–ø–∞ –∏ –Ω–∞—Ö–æ–¥–∏—Ç —Å–≤—è–∑–∞–Ω–Ω—ã–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è.
"""
import re
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
import json

@dataclass
class Event:
    """–°–æ–±—ã—Ç–∏–µ —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π."""
    timestamp: datetime
    event_type: str
    task_id: Optional[int]
    item_id: Optional[int]
    details: str
    log_file: str

class FullCycleAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞."""
    
    def __init__(self, logs_dir: Path):
        self.logs_dir = logs_dir
        self.events: List[Event] = []
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞
        self.patterns = {
            # 1. –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏ —á–µ—Ä–µ–∑ Telegram
            'task_created': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*‚úÖ –ó–∞–¥–∞—á–∞ —Å–æ–∑–¥–∞–Ω–∞.*ID: #(\d+)'),
            'task_added_to_monitoring': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*–î–æ–±–∞–≤–ª–µ–Ω–∞ –∑–∞–¥–∞—á–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞:.*\(ID: (\d+)\)'),
            
            # 2. –ó–∞–ø—É—Å–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
            'monitoring_started': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*üöÄ –ó–∞–ø—É—â–µ–Ω –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –¥–ª—è –∑–∞–¥–∞—á–∏:.*\(ID: (\d+)\)'),
            'first_check_scheduled': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*–ó–∞–¥–∞—á–∞ (\d+): –ü–µ—Ä–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —Å—Ä–∞–∑—É'),
            
            # 3. –¶–∏–∫–ª –ø—Ä–æ–≤–µ—Ä–∫–∏
            'check_started': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*–ó–∞–¥–∞—á–∞ (\d+): –ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É'),
            'task_published_redis': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*–ó–∞–¥–∞—á–∞ (\d+): –ü—É–±–ª–∏–∫—É–µ–º –∑–∞–¥–∞—á—É –≤ Redis –∫–∞–Ω–∞–ª'),
            'task_published_success': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*–ó–∞–¥–∞—á–∞ (\d+): –£—Å–ø–µ—à–Ω–æ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–∞ –≤ Redis'),
            
            # 4. –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤ Parsing Worker
            'task_received_worker': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*ParsingWorker: –ü–æ–ª—É—á–µ–Ω–∞ –∑–∞–¥–∞—á–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: task_id=(\d+)'),
            'parsing_started': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*üîç –í—ã–ø–æ–ª–Ω—è–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –¥–ª—è –∑–∞–¥–∞—á–∏ (\d+):'),
            'parsing_completed': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*üìä –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–ª—è –∑–∞–¥–∞—á–∏ (\d+):.*success=(\w+).*items=(\d+)'),
            
            # 5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥–º–µ—Ç–æ–≤
            'item_found': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*‚úÖ –ü—Ä–µ–¥–º–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è:.*\(\$[\d.]+\)'),
            'items_saved': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ (\d+) –ø—Ä–µ–¥–º–µ—Ç–æ–≤ –¥–ª—è –∑–∞–¥–∞—á–∏ (\d+)'),
            
            # 6. –ü—É–±–ª–∏–∫–∞—Ü–∏—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
            'notification_publishing': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*üì§ ParsingWorker: –ü—É–±–ª–∏–∫—É–µ–º (\d+) —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –≤ Redis'),
            'notification_published': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*üì§ ParsingWorker: –ü—É–±–ª–∏–∫—É–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –¥–ª—è –ø—Ä–µ–¥–º–µ—Ç–∞ (\d+)'),
            'notification_published_success': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*‚úÖ ParsingWorker: –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –¥–ª—è –ø—Ä–µ–¥–º–µ—Ç–∞ (\d+) –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ'),
            
            # 7. –ü–æ–ª—É—á–µ–Ω–∏–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –≤ Telegram –±–æ—Ç–µ
            'notification_received_bot': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*üì• TelegramBot: –ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–∑ Redis.*found_item'),
            'notification_processing': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*üîî TelegramBot: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –Ω–∞–π–¥–µ–Ω–Ω–æ–º –ø—Ä–µ–¥–º–µ—Ç–µ: item_id=(\d+)'),
            'notification_sending': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*üì§ TelegramBot: –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –≤ Telegram'),
            'notification_sent': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*‚úÖ TelegramBot.*–£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –¥–ª—è –ø—Ä–µ–¥–º–µ—Ç–∞.*\(ID: (\d+)\)'),
            
            # 8. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            'stats_updated': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞–¥–∞—á–∏ (\d+) –æ–±–Ω–æ–≤–ª–µ–Ω–∞.*–Ω–∞–π–¥–µ–Ω–æ=(\d+)'),
        }
    
    def parse_logs(self, date_filter: Optional[str] = None):
        """–ü–∞—Ä—Å–∏—Ç –ª–æ–≥–∏ –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Å–æ–±—ã—Ç–∏—è."""
        log_files = []
        
        if date_filter:
            for pattern in ['telegram_bot_*.log', 'parsing_worker_*.log', 'steam_monitor_*.log']:
                log_files.extend(self.logs_dir.glob(pattern.replace('*', f'*{date_filter}*')))
        else:
            for pattern in ['telegram_bot_*.log', 'parsing_worker_*.log', 'steam_monitor_*.log']:
                log_files.extend(self.logs_dir.glob(pattern))
        
        print(f"üìÅ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {len(log_files)} —Ñ–∞–π–ª–æ–≤ –ª–æ–≥–æ–≤...")
        
        for log_file in sorted(log_files):
            print(f"   üìÑ {log_file.name}")
            self._parse_log_file(log_file)
        
        self.events.sort(key=lambda e: e.timestamp)
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(self.events)} —Å–æ–±—ã—Ç–∏–π")
    
    def _parse_log_file(self, log_file: Path):
        """–ü–∞—Ä—Å–∏—Ç –æ–¥–∏–Ω —Ñ–∞–π–ª –ª–æ–≥–∞."""
        try:
            with open(log_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    for event_type, pattern in self.patterns.items():
                        match = pattern.search(line)
                        if match:
                            try:
                                timestamp = datetime.strptime(match.group(1), '%Y-%m-%d %H:%M:%S')
                                
                                # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Å–æ–±—ã—Ç–∏—è
                                task_id = None
                                item_id = None
                                
                                if event_type in ['task_created', 'task_added_to_monitoring', 'monitoring_started', 
                                                'first_check_scheduled', 'check_started', 'task_published_redis',
                                                'task_published_success', 'task_received_worker', 'parsing_started',
                                                'parsing_completed', 'items_saved', 'stats_updated']:
                                    task_id = int(match.group(2))
                                elif event_type in ['notification_published', 'notification_published_success',
                                                  'notification_processing', 'notification_sent']:
                                    item_id = int(match.group(2))
                                
                                event = Event(
                                    timestamp=timestamp,
                                    event_type=event_type,
                                    task_id=task_id,
                                    item_id=item_id,
                                    details=line.strip(),
                                    log_file=log_file.name
                                )
                                self.events.append(event)
                            except (ValueError, IndexError) as e:
                                continue
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {log_file}: {e}")
    
    def analyze_full_cycle(self, task_id: int) -> Dict:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –¥–ª—è –∑–∞–¥–∞—á–∏."""
        task_events = [e for e in self.events if e.task_id == task_id]
        
        if not task_events:
            return {"error": f"–°–æ–±—ã—Ç–∏—è –¥–ª—è –∑–∞–¥–∞—á–∏ {task_id} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"}
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Å–æ–±—ã—Ç–∏—è –ø–æ —Ç–∏–ø–∞–º
        events_by_type = {}
        for event in task_events:
            if event.event_type not in events_by_type:
                events_by_type[event.event_type] = []
            events_by_type[event.event_type].append(event)
        
        # –°—Ç—Ä–æ–∏–º –≤—Ä–µ–º–µ–Ω–Ω—É—é —à–∫–∞–ª—É
        timeline = {}
        
        # –≠—Ç–∞–ø 1: –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏
        if 'task_created' in events_by_type:
            timeline['1_task_created'] = events_by_type['task_created'][0].timestamp
        elif 'task_added_to_monitoring' in events_by_type:
            timeline['1_task_created'] = events_by_type['task_added_to_monitoring'][0].timestamp
        
        # –≠—Ç–∞–ø 2: –ó–∞–ø—É—Å–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        if 'monitoring_started' in events_by_type:
            timeline['2_monitoring_started'] = events_by_type['monitoring_started'][0].timestamp
        
        # –≠—Ç–∞–ø 3: –ü–µ—Ä–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
        if 'check_started' in events_by_type:
            timeline['3_first_check'] = events_by_type['check_started'][0].timestamp
        
        # –≠—Ç–∞–ø 4: –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ Redis
        if 'task_published_success' in events_by_type:
            timeline['4_redis_published'] = events_by_type['task_published_success'][0].timestamp
        
        # –≠—Ç–∞–ø 5: –ü–æ–ª—É—á–µ–Ω–∏–µ –≤–æ—Ä–∫–µ—Ä–æ–º
        if 'task_received_worker' in events_by_type:
            timeline['5_worker_received'] = events_by_type['task_received_worker'][0].timestamp
        
        # –≠—Ç–∞–ø 6: –ù–∞—á–∞–ª–æ –ø–∞—Ä—Å–∏–Ω–≥–∞
        if 'parsing_started' in events_by_type:
            timeline['6_parsing_started'] = events_by_type['parsing_started'][0].timestamp
        
        # –≠—Ç–∞–ø 7: –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –ø–∞—Ä—Å–∏–Ω–≥–∞
        if 'parsing_completed' in events_by_type:
            timeline['7_parsing_completed'] = events_by_type['parsing_completed'][0].timestamp
        
        # –≠—Ç–∞–ø 8: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥–º–µ—Ç–æ–≤ (–µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã)
        if 'items_saved' in events_by_type:
            timeline['8_items_saved'] = events_by_type['items_saved'][0].timestamp
        
        # –≠—Ç–∞–ø 9: –ü—É–±–ª–∏–∫–∞—Ü–∏—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π (–µ—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–µ–¥–º–µ—Ç—ã)
        if 'notification_published_success' in events_by_type:
            timeline['9_notifications_published'] = events_by_type['notification_published_success'][0].timestamp
        
        # –≠—Ç–∞–ø 10: –û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π (–µ—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–µ–¥–º–µ—Ç—ã)
        # –ò—â–µ–º —Å–≤—è–∑–∞–Ω–Ω—ã–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        notification_events = [e for e in self.events if e.event_type == 'notification_sent']
        if notification_events and timeline:
            # –ò—â–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è, –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–¥–∞—á–∏
            task_start = min(timeline.values())
            related_notifications = [e for e in notification_events if e.timestamp >= task_start]
            if related_notifications:
                timeline['10_notification_sent'] = related_notifications[0].timestamp
        
        # –í—ã—á–∏—Å–ª—è–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
        intervals = {}
        timeline_keys = sorted(timeline.keys())
        
        for i in range(len(timeline_keys) - 1):
            current_key = timeline_keys[i]
            next_key = timeline_keys[i + 1]
            interval = timeline[next_key] - timeline[current_key]
            intervals[f"{current_key}_to_{next_key}"] = interval.total_seconds()
        
        return {
            "task_id": task_id,
            "timeline": timeline,
            "intervals": intervals,
            "events_by_type": {k: len(v) for k, v in events_by_type.items()},
            "total_events": len(task_events),
            "total_time": (max(timeline.values()) - min(timeline.values())).total_seconds() if timeline else 0
        }
    
    def print_full_cycle_analysis(self, task_id: int):
        """–í—ã–≤–æ–¥–∏—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞."""
        analysis = self.analyze_full_cycle(task_id)
        
        if "error" in analysis:
            print(f"‚ùå {analysis['error']}")
            return
        
        print(f"\nüîÑ –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –¥–ª—è –∑–∞–¥–∞—á–∏ #{task_id}")
        print("=" * 80)
        
        timeline = analysis['timeline']
        intervals = analysis['intervals']
        
        # –í—Ä–µ–º–µ–Ω–Ω–∞—è —à–∫–∞–ª–∞ —Å –æ–ø–∏—Å–∞–Ω–∏—è–º–∏ —ç—Ç–∞–ø–æ–≤
        stage_descriptions = {
            '1_task_created': '1Ô∏è‚É£ –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏ —á–µ—Ä–µ–∑ Telegram',
            '2_monitoring_started': '2Ô∏è‚É£ –ó–∞–ø—É—Å–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞',
            '3_first_check': '3Ô∏è‚É£ –ü–µ—Ä–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞',
            '4_redis_published': '4Ô∏è‚É£ –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ Redis',
            '5_worker_received': '5Ô∏è‚É£ –ü–æ–ª—É—á–µ–Ω–∏–µ –≤–æ—Ä–∫–µ—Ä–æ–º',
            '6_parsing_started': '6Ô∏è‚É£ –ù–∞—á–∞–ª–æ –ø–∞—Ä—Å–∏–Ω–≥–∞',
            '7_parsing_completed': '7Ô∏è‚É£ –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –ø–∞—Ä—Å–∏–Ω–≥–∞',
            '8_items_saved': '8Ô∏è‚É£ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥–º–µ—Ç–æ–≤',
            '9_notifications_published': '9Ô∏è‚É£ –ü—É–±–ª–∏–∫–∞—Ü–∏—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π',
            '10_notification_sent': 'üîü –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ Telegram'
        }
        
        print(f"üìÖ –í—Ä–µ–º–µ–Ω–Ω–∞—è —à–∫–∞–ª–∞:")
        for stage in sorted(timeline.keys()):
            timestamp = timeline[stage]
            description = stage_descriptions.get(stage, stage)
            print(f"   {description:35} | {timestamp.strftime('%H:%M:%S.%f')[:-3]}")
        
        print(f"\n‚è±Ô∏è –í—Ä–µ–º—è –º–µ–∂–¥—É —ç—Ç–∞–ø–∞–º–∏:")
        for interval_name, seconds in intervals.items():
            parts = interval_name.split('_to_')
            if len(parts) == 2:
                from_desc = stage_descriptions.get(parts[0], parts[0])
                to_desc = stage_descriptions.get(parts[1], parts[1])
                print(f"   {from_desc} ‚Üí {to_desc}")
                print(f"   {'':35} | {seconds:8.3f} —Å–µ–∫")
        
        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   –í—Å–µ–≥–æ —Å–æ–±—ã—Ç–∏–π: {analysis['total_events']}")
        print(f"   –û–±—â–µ–µ –≤—Ä–µ–º—è:   {analysis['total_time']:.3f} —Å–µ–∫ ({analysis['total_time']/60:.1f} –º–∏–Ω)")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ–±—ã—Ç–∏—è –ø–æ —Ç–∏–ø–∞–º
        print(f"\nüìã –°–æ–±—ã—Ç–∏—è –ø–æ —Ç–∏–ø–∞–º:")
        for event_type, count in analysis['events_by_type'].items():
            print(f"   {event_type:25} | {count:3d}")
        
        # –°–∞–º—ã–µ –º–µ–¥–ª–µ–Ω–Ω—ã–µ —ç—Ç–∞–ø—ã
        if intervals:
            sorted_intervals = sorted(intervals.items(), key=lambda x: x[1], reverse=True)
            print(f"\nüêå –°–∞–º—ã–µ –º–µ–¥–ª–µ–Ω–Ω—ã–µ —ç—Ç–∞–ø—ã:")
            for i, (interval_name, seconds) in enumerate(sorted_intervals[:3]):
                parts = interval_name.split('_to_')
                if len(parts) == 2:
                    from_desc = stage_descriptions.get(parts[0], parts[0])
                    to_desc = stage_descriptions.get(parts[1], parts[1])
                    print(f"   {i+1}. {from_desc} ‚Üí {to_desc}")
                    print(f"      {seconds:.3f} —Å–µ–∫ ({seconds/60:.1f} –º–∏–Ω)")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    logs_dir = Path(__file__).parent.parent / "logs"
    
    if not logs_dir.exists():
        print(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ª–æ–≥–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {logs_dir}")
        return
    
    analyzer = FullCycleAnalyzer(logs_dir)
    
    # –ü–∞—Ä—Å–∏–º –ª–æ–≥–∏ –∑–∞ —Å–µ–≥–æ–¥–Ω—è
    today = datetime.now().strftime('%Y-%m-%d')
    print(f"üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –∑–∞ {today}...")
    analyzer.parse_logs(date_filter=today)
    
    if len(sys.argv) > 1:
        try:
            task_id = int(sys.argv[1])
            analyzer.print_full_cycle_analysis(task_id)
        except ValueError:
            print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π ID –∑–∞–¥–∞—á–∏. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: python analyze_full_cycle.py <task_id>")
    else:
        print("\nüí° –î–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:")
        print("   python3 analyze_full_cycle.py <task_id>")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∑–∞–¥–∞—á–∏
        task_events = {}
        for event in analyzer.events:
            if event.task_id:
                if event.task_id not in task_events:
                    task_events[event.task_id] = 0
                task_events[event.task_id] += 1
        
        if task_events:
            print(f"\nüìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –∑–∞–¥–∞—á–∏ –∑–∞ —Å–µ–≥–æ–¥–Ω—è:")
            for task_id, event_count in sorted(task_events.items()):
                print(f"   –ó–∞–¥–∞—á–∞ #{task_id}: {event_count} —Å–æ–±—ã—Ç–∏–π")

if __name__ == "__main__":
    main()
