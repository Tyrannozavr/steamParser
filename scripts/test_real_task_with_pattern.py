#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–∞–ª—å–Ω–æ–π –∑–∞–¥–∞—á–∏ —Å –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º –∏–∑ –ë–î.
–ù–∞—Ö–æ–¥–∏—Ç –∑–∞–¥–∞—á—É —Å –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º, –∑–∞–ø—É—Å–∫–∞–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥ –∏ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.
"""
import asyncio
import sys
import json
import random
from pathlib import Path
from datetime import datetime

sys.path.insert(0, str(Path(__file__).parent.parent))

from sqlalchemy import select
from core import DatabaseManager, MonitoringTask, FoundItem
from services.parsing_service import ParsingService
from services.proxy_manager_factory import ProxyManagerFactory
from services.redis_service import RedisService
from core.config import Config
from loguru import logger

logger.remove()
logger.add(sys.stderr, level="INFO", format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | <level>{message}</level>")


async def find_task_with_pattern(db_session):
    """–ù–∞—Ö–æ–¥–∏—Ç –∑–∞–¥–∞—á—É —Å –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º –∏–∑ –ë–î."""
    logger.info("üîç –ò—â–µ–º –∑–∞–¥–∞—á—É —Å –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º...")
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏
    result = await db_session.execute(
        select(MonitoringTask)
        .where(MonitoringTask.is_active == True)
        .order_by(MonitoringTask.id)
    )
    tasks = result.scalars().all()
    
    if not tasks:
        logger.error("‚ùå –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á –≤ –ë–î")
        return None
    
    logger.info(f"üìã –ù–∞–π–¥–µ–Ω–æ {len(tasks)} –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á")
    
    # –ò—â–µ–º –∑–∞–¥–∞—á–∏ —Å –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏
    tasks_with_patterns = []
    for task in tasks:
        try:
            filters_json = task.filters_json
            if isinstance(filters_json, str):
                filters_json = json.loads(filters_json)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
            if isinstance(filters_json, dict):
                pattern_list = filters_json.get('pattern_list')
                if pattern_list and isinstance(pattern_list, dict):
                    patterns = pattern_list.get('patterns', [])
                    if patterns:
                        tasks_with_patterns.append((task, patterns))
        except Exception as e:
            logger.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –∑–∞–¥–∞—á–∏ {task.id}: {e}")
            continue
    
    if not tasks_with_patterns:
        logger.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∑–∞–¥–∞—á —Å –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—É—é –∑–∞–¥–∞—á—É")
        return tasks[0], None
    
    # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—É—é –∑–∞–¥–∞—á—É —Å –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º
    task, patterns = random.choice(tasks_with_patterns)
    logger.info(f"‚úÖ –í—ã–±—Ä–∞–Ω–∞ –∑–∞–¥–∞—á–∞ ID={task.id}: '{task.name}'")
    logger.info(f"   –ü—Ä–µ–¥–º–µ—Ç: {task.item_name}")
    logger.info(f"   –ü–∞—Ç—Ç–µ—Ä–Ω—ã: {patterns}")
    logger.info(f"   –ü—Ä–æ–≤–µ—Ä–æ–∫: {task.total_checks}, –ù–∞–π–¥–µ–Ω–æ: {task.items_found}")
    
    return task, patterns


async def run_parsing_test(task: MonitoringTask, db_session, redis_service, proxy_manager):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥ –¥–ª—è –∑–∞–¥–∞—á–∏ –∏ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã."""
    logger.info("=" * 70)
    logger.info(f"üöÄ –ó–ê–ü–£–°–ö –ü–ê–†–°–ò–ù–ì–ê –¥–ª—è –∑–∞–¥–∞—á–∏ {task.id}")
    logger.info("=" * 70)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∑–∞–¥–∞—á—É –∑–∞–Ω–æ–≤–æ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    await db_session.refresh(task)
    
    initial_checks = task.total_checks
    initial_found = task.items_found
    initial_last_check = task.last_check
    
    logger.info(f"üìä –ù–∞—á–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ:")
    logger.info(f"   –ü—Ä–æ–≤–µ—Ä–æ–∫: {initial_checks}")
    logger.info(f"   –ù–∞–π–¥–µ–Ω–æ: {initial_found}")
    logger.info(f"   –ü–æ—Å–ª–µ–¥–Ω—è—è –ø—Ä–æ–≤–µ—Ä–∫–∞: {initial_last_check}")
    
    # –°–æ–∑–¥–∞–µ–º ParsingService
    parsing_service = ParsingService(
        db_session=db_session,
        proxy_manager=proxy_manager,
        redis_service=redis_service
    )
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
    from core.models import SearchFilters
    filters_json = task.filters_json
    if isinstance(filters_json, str):
        filters_json = json.loads(filters_json)
    
    filters = SearchFilters.model_validate(filters_json)
    filters.item_name = task.item_name
    
    logger.info(f"üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –¥–ª—è '{task.item_name}'...")
    logger.info(f"   –§–∏–ª—å—Ç—Ä—ã: –ø–∞—Ç—Ç–µ—Ä–Ω—ã={filters.pattern_list.patterns if filters.pattern_list else '–Ω–µ—Ç'}")
    
    start_time = datetime.now()
    
    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥
        result = await parsing_service.parse_items(
            item_name=task.item_name,
            filters=filters,
            appid=task.appid,
            currency=task.currency
        )
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        logger.info("=" * 70)
        logger.info(f"‚úÖ –ü–ê–†–°–ò–ù–ì –ó–ê–í–ï–†–®–ï–ù –∑–∞ {duration:.1f} —Å–µ–∫—É–Ω–¥")
        logger.info("=" * 70)
        logger.info(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç:")
        logger.info(f"   –£—Å–ø–µ—Ö: {result.get('success', False)}")
        logger.info(f"   –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ: {result.get('total', 0)}")
        logger.info(f"   –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {result.get('filtered', 0)}")
        logger.info(f"   –ü—Ä–µ–¥–º–µ—Ç–æ–≤ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ: {len(result.get('items', []))}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏ –≤ –ë–î
        await db_session.refresh(task)
        
        final_checks = task.total_checks
        final_found = task.items_found
        final_last_check = task.last_check
        
        logger.info("=" * 70)
        logger.info(f"üìä –§–ò–ù–ê–õ–¨–ù–û–ï –°–û–°–¢–û–Ø–ù–ò–ï –ó–ê–î–ê–ß–ò:")
        logger.info("=" * 70)
        logger.info(f"   –ü—Ä–æ–≤–µ—Ä–æ–∫: {initial_checks} ‚Üí {final_checks} (–∏–∑–º–µ–Ω–µ–Ω–∏–µ: {final_checks - initial_checks:+d})")
        logger.info(f"   –ù–∞–π–¥–µ–Ω–æ: {initial_found} ‚Üí {final_found} (–∏–∑–º–µ–Ω–µ–Ω–∏–µ: {final_found - initial_found:+d})")
        logger.info(f"   –ü–æ—Å–ª–µ–¥–Ω—è—è –ø—Ä–æ–≤–µ—Ä–∫–∞: {initial_last_check} ‚Üí {final_last_check}")
        logger.info(f"   next_check: {task.next_check}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª–∏ –ª–∏ –Ω–∞–π–¥–µ–Ω—ã –Ω–æ–≤—ã–µ –ø—Ä–µ–¥–º–µ—Ç—ã
        if result.get('items'):
            logger.info(f"\nüéØ –ù–ê–ô–î–ï–ù–û {len(result['items'])} –ü–û–î–•–û–î–Ø–©–ò–• –ü–†–ï–î–ú–ï–¢–û–í:")
            for i, item in enumerate(result['items'][:5], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                parsed_data = item.get('parsed_data', {})
                price = item.get('sell_price_text', 'N/A')
                pattern = parsed_data.get('pattern', 'N/A')
                float_val = parsed_data.get('float', 'N/A')
                logger.info(f"   {i}. –¶–µ–Ω–∞: {price}, –ü–∞—Ç—Ç–µ—Ä–Ω: {pattern}, Float: {float_val}")
            
            if len(result['items']) > 5:
                logger.info(f"   ... –∏ –µ—â–µ {len(result['items']) - 5} –ø—Ä–µ–¥–º–µ—Ç–æ–≤")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª–∏ –ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –ø—Ä–µ–¥–º–µ—Ç—ã –≤ –ë–î
        found_items_result = await db_session.execute(
            select(FoundItem)
            .where(FoundItem.task_id == task.id)
            .order_by(FoundItem.found_at.desc())
            .limit(10)
        )
        recent_items = found_items_result.scalars().all()
        
        if recent_items:
            logger.info(f"\nüíæ –ü–û–°–õ–ï–î–ù–ò–ï –°–û–•–†–ê–ù–ï–ù–ù–´–ï –ü–†–ï–î–ú–ï–¢–´ –í –ë–î:")
            for item in recent_items[:5]:
                logger.info(f"   ID={item.id}: {item.item_name} (${item.price:.2f}), –Ω–∞–π–¥–µ–Ω–æ: {item.found_at}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–∏–ª–∏—Å—å
        if final_checks > initial_checks:
            logger.info(f"\n‚úÖ –°—á–µ—Ç—á–∏–∫ –ø—Ä–æ–≤–µ—Ä–æ–∫ –æ–±–Ω–æ–≤–ª–µ–Ω: {initial_checks} ‚Üí {final_checks}")
        else:
            logger.warning(f"\n‚ö†Ô∏è –°—á–µ—Ç—á–∏–∫ –ø—Ä–æ–≤–µ—Ä–æ–∫ –ù–ï –æ–±–Ω–æ–≤–ª–µ–Ω: {initial_checks} ‚Üí {final_checks}")
        
        if final_last_check and final_last_check != initial_last_check:
            logger.info(f"‚úÖ last_check –æ–±–Ω–æ–≤–ª–µ–Ω: {initial_last_check} ‚Üí {final_last_check}")
        else:
            logger.warning(f"‚ö†Ô∏è last_check –ù–ï –æ–±–Ω–æ–≤–ª–µ–Ω")
        
        if task.next_check:
            logger.info(f"‚úÖ next_check —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {task.next_check}")
        else:
            logger.warning(f"‚ö†Ô∏è next_check –ù–ï —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        
        return result
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return None


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    logger.info("=" * 70)
    logger.info("üß™ –¢–ï–°–¢ –†–ï–ê–õ–¨–ù–û–ô –ó–ê–î–ê–ß–ò –° –ü–ê–¢–¢–ï–†–ù–û–ú")
    logger.info("=" * 70)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ë–î
    db_manager = DatabaseManager(Config.DATABASE_URL)
    await db_manager.init_db()
    db_session = await db_manager.get_session()
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Redis
        redis_service = RedisService(redis_url=Config.REDIS_URL)
        if Config.REDIS_ENABLED:
            await redis_service.connect()
            logger.info("‚úÖ Redis –ø–æ–¥–∫–ª—é—á–µ–Ω")
        else:
            logger.warning("‚ö†Ô∏è Redis –æ—Ç–∫–ª—é—á–µ–Ω")
            redis_service = None
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º ProxyManager
        proxy_manager = await ProxyManagerFactory.get_instance(
            db_session=db_session,
            redis_service=redis_service
        )
        logger.info("‚úÖ ProxyManager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        
        # –ù–∞—Ö–æ–¥–∏–º –∑–∞–¥–∞—á—É —Å –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º
        task_data = await find_task_with_pattern(db_session)
        if not task_data:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∑–∞–¥–∞—á—É –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
            return
        
        task, patterns = task_data
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥
        result = await run_parsing_test(task, db_session, redis_service, proxy_manager)
        
        if result:
            logger.info("\n" + "=" * 70)
            logger.info("‚úÖ –¢–ï–°–¢ –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û")
            logger.info("=" * 70)
        else:
            logger.error("\n" + "=" * 70)
            logger.error("‚ùå –¢–ï–°–¢ –ó–ê–í–ï–†–®–ï–ù –° –û–®–ò–ë–ö–ê–ú–ò")
            logger.error("=" * 70)
        
    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        logger.error(traceback.format_exc())
    finally:
        await db_session.close()
        await db_manager.close()
        if redis_service:
            await redis_service.disconnect()


if __name__ == "__main__":
    asyncio.run(main())
