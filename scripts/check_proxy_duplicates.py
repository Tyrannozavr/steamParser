#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø—Ä–æ–∫—Å–∏ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö (—Ç–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä–∫–∞, –±–µ–∑ —É–¥–∞–ª–µ–Ω–∏—è).
"""
import asyncio
import sys
from pathlib import Path
from collections import defaultdict

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent.parent))

from core import DatabaseManager, Proxy
from services import ProxyManager
from core.config import Config
from loguru import logger
from sqlalchemy import select


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    logger.info("üîç –ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø—Ä–æ–∫—Å–∏...")
    
    db_manager = DatabaseManager(Config.DATABASE_URL)
    await db_manager.init_db()
    
    try:
        session = await db_manager.get_session()
        proxy_manager = ProxyManager(session, redis_service=None)
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –ø—Ä–æ–∫—Å–∏
        result = await session.execute(
            select(Proxy).order_by(Proxy.id)
        )
        all_proxies = list(result.scalars().all())
        
        logger.info(f"üìã –í—Å–µ–≥–æ –ø—Ä–æ–∫—Å–∏ –≤ –ë–î: {len(all_proxies)}")
        logger.info("=" * 70)
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É URL
        normalized_groups: dict[str, list[Proxy]] = defaultdict(list)
        for proxy in all_proxies:
            normalized = ProxyManager._normalize_proxy_url(proxy.url)
            normalized_groups[normalized].append(proxy)
        
        # –ù–∞—Ö–æ–¥–∏–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        duplicates_found = 0
        total_duplicates = 0
        
        logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã...")
        logger.info("=" * 70)
        
        for normalized_url, proxies in sorted(normalized_groups.items()):
            if len(proxies) > 1:
                duplicates_found += 1
                total_duplicates += len(proxies) - 1
                
                logger.info(f"\nüî¥ –î–£–ë–õ–ò–ö–ê–¢–´ –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ URL: {normalized_url}")
                proxies_sorted = sorted(proxies, key=lambda p: p.id)
                logger.info(f"   ‚úÖ –û—Å—Ç–∞–≤–∏—Ç—å (—Å–∞–º—ã–π —Å—Ç–∞—Ä—ã–π): ID={proxies_sorted[0].id}, URL={proxies_sorted[0].url}")
                for dup in proxies_sorted[1:]:
                    logger.info(f"   ‚ùå –£–¥–∞–ª–∏—Ç—å: ID={dup.id}, URL={dup.url}")
        
        logger.info("=" * 70)
        logger.info("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–†–û–í–ï–†–ö–ò:")
        logger.info("=" * 70)
        logger.info(f"üìã –í—Å–µ–≥–æ –ø—Ä–æ–∫—Å–∏: {len(all_proxies)}")
        logger.info(f"üìã –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö URL: {len(normalized_groups)}")
        logger.info(f"üî¥ –ì—Ä—É–ø–ø —Å –¥—É–±–ª–∏–∫–∞—Ç–∞–º–∏: {duplicates_found}")
        logger.info(f"üóëÔ∏è –ü—Ä–æ–∫—Å–∏-–¥—É–±–ª–∏–∫–∞—Ç–æ–≤ (–∫ —É–¥–∞–ª–µ–Ω–∏—é): {total_duplicates}")
        logger.info("=" * 70)
        
        if duplicates_found == 0:
            logger.info("‚úÖ –î—É–±–ª–∏–∫–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ! –í—Å–µ –ø—Ä–æ–∫—Å–∏ —É–Ω–∏–∫–∞–ª—å–Ω—ã.")
        else:
            logger.info(f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ {duplicates_found} –≥—Ä—É–ø–ø –¥—É–±–ª–∏–∫–∞—Ç–æ–≤!")
            logger.info(f"üí° –ó–∞–ø—É—Å—Ç–∏—Ç–µ cleanup_proxy_duplicates.py –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
        
        await session.close()
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {e}")
        import traceback
        logger.error(traceback.format_exc())
    finally:
        await db_manager.close()


if __name__ == "__main__":
    asyncio.run(main())

