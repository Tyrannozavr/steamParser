#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç—Ç–∞–ø–æ–≤ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ Steam Market.
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ª–æ–≥–∏ –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—Ä–µ–º—è –∫–∞–∂–¥–æ–≥–æ —ç—Ç–∞–ø–∞ –æ—Ç –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ –¥–æ –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è.
"""
import re
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
import json

@dataclass
class TimingEvent:
    """–°–æ–±—ã—Ç–∏–µ —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π."""
    timestamp: datetime
    event_type: str
    task_id: Optional[int]
    item_id: Optional[int]
    details: str
    log_file: str

class TimingAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —ç—Ç–∞–ø–æ–≤."""
    
    def __init__(self, logs_dir: Path):
        self.logs_dir = logs_dir
        self.events: List[TimingEvent] = []
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–æ–±—ã—Ç–∏–π –∏–∑ –ª–æ–≥–æ–≤
        self.patterns = {
            # –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏ –≤ Telegram –±–æ—Ç–µ
            'task_created': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*–î–æ–±–∞–≤–ª–µ–Ω–∞ –∑–∞–¥–∞—á–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞:.*\(ID: (\d+)\)'),
            
            # –ó–∞–ø—É—Å–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∑–∞–¥–∞—á–∏
            'monitoring_started': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*–ó–∞–ø—É—â–µ–Ω –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –¥–ª—è –∑–∞–¥–∞—á–∏:.*\(ID: (\d+)\)'),
            
            # –ü—É–±–ª–∏–∫–∞—Ü–∏—è –∑–∞–¥–∞—á–∏ –≤ Redis
            'task_published': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*–ó–∞–¥–∞—á–∞ (\d+): –ü—É–±–ª–∏–∫—É–µ–º –∑–∞–¥–∞—á—É –≤ Redis –∫–∞–Ω–∞–ª'),
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏ Parsing Worker
            'task_received': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*ParsingWorker: –ü–æ–ª—É—á–µ–Ω–∞ –∑–∞–¥–∞—á–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: task_id=(\d+)'),
            
            # –ù–∞—á–∞–ª–æ –ø–∞—Ä—Å–∏–Ω–≥–∞
            'parsing_started': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*–í—ã–ø–æ–ª–Ω—è–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –¥–ª—è –∑–∞–¥–∞—á–∏ (\d+):'),
            
            # –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞
            'parsing_completed': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–ª—è –∑–∞–¥–∞—á–∏ (\d+):.*success=(\w+).*items=(\d+)'),
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥–º–µ—Ç–∞
            'item_saved': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*–ü—Ä–µ–¥–º–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è:.*\(\$[\d.]+\)'),
            
            # –ü—É–±–ª–∏–∫–∞—Ü–∏—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –≤ Redis
            'notification_published': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*ParsingWorker: –ü—É–±–ª–∏–∫—É–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –¥–ª—è –ø—Ä–µ–¥–º–µ—Ç–∞ (\d+)'),
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è Telegram –±–æ—Ç–æ–º
            'notification_received': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*TelegramBot: –ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–∑ Redis.*found_item'),
            
            # –û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –≤ Telegram
            'notification_sent': re.compile(r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*TelegramBot.*–£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –¥–ª—è –ø—Ä–µ–¥–º–µ—Ç–∞.*\(ID: (\d+)\)'),
        }
    
    def parse_logs(self, date_filter: Optional[str] = None):
        """–ü–∞—Ä—Å–∏—Ç –ª–æ–≥–∏ –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Å–æ–±—ã—Ç–∏—è."""
        log_files = []
        
        if date_filter:
            # –ò—â–µ–º –ª–æ–≥–∏ –∑–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –¥–∞—Ç—É
            for pattern in ['telegram_bot_*.log', 'parsing_worker_*.log', 'steam_monitor_*.log']:
                log_files.extend(self.logs_dir.glob(pattern.replace('*', f'*{date_filter}*')))
        else:
            # –ë–µ—Ä–µ–º –≤—Å–µ –ª–æ–≥–∏
            for pattern in ['telegram_bot_*.log', 'parsing_worker_*.log', 'steam_monitor_*.log']:
                log_files.extend(self.logs_dir.glob(pattern))
        
        print(f"üìÅ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {len(log_files)} —Ñ–∞–π–ª–æ–≤ –ª–æ–≥–æ–≤...")
        
        for log_file in sorted(log_files):
            print(f"   üìÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: {log_file.name}")
            self._parse_log_file(log_file)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å–æ–±—ã—Ç–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        self.events.sort(key=lambda e: e.timestamp)
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(self.events)} —Å–æ–±—ã—Ç–∏–π")
    
    def _parse_log_file(self, log_file: Path):
        """–ü–∞—Ä—Å–∏—Ç –æ–¥–∏–Ω —Ñ–∞–π–ª –ª–æ–≥–∞."""
        try:
            with open(log_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    for event_type, pattern in self.patterns.items():
                        match = pattern.search(line)
                        if match:
                            try:
                                timestamp = datetime.strptime(match.group(1), '%Y-%m-%d %H:%M:%S')
                                
                                # –ò–∑–≤–ª–µ–∫–∞–µ–º task_id –∏ item_id –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Å–æ–±—ã—Ç–∏—è
                                task_id = None
                                item_id = None
                                
                                if event_type in ['task_created', 'monitoring_started', 'task_published', 
                                                'task_received', 'parsing_started', 'parsing_completed']:
                                    task_id = int(match.group(2))
                                elif event_type in ['notification_published', 'notification_sent']:
                                    item_id = int(match.group(2))
                                
                                event = TimingEvent(
                                    timestamp=timestamp,
                                    event_type=event_type,
                                    task_id=task_id,
                                    item_id=item_id,
                                    details=line.strip(),
                                    log_file=log_file.name
                                )
                                self.events.append(event)
                            except (ValueError, IndexError) as e:
                                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–æ–∫–∏ {line_num} –≤ {log_file.name}: {e}")
                                continue
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {log_file}: {e}")
    
    def analyze_task_timing(self, task_id: int) -> Dict[str, any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏."""
        task_events = [e for e in self.events if e.task_id == task_id]
        
        if not task_events:
            return {"error": f"–°–æ–±—ã—Ç–∏—è –¥–ª—è –∑–∞–¥–∞—á–∏ {task_id} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"}
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Å–æ–±—ã—Ç–∏—è –ø–æ —Ç–∏–ø–∞–º
        events_by_type = {}
        for event in task_events:
            if event.event_type not in events_by_type:
                events_by_type[event.event_type] = []
            events_by_type[event.event_type].append(event)
        
        # –ù–∞—Ö–æ–¥–∏–º –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã –≤—Ä–µ–º–µ–Ω–∏
        timeline = {}
        
        if 'task_created' in events_by_type:
            timeline['task_created'] = events_by_type['task_created'][0].timestamp
        
        if 'monitoring_started' in events_by_type:
            timeline['monitoring_started'] = events_by_type['monitoring_started'][0].timestamp
        
        if 'task_published' in events_by_type:
            timeline['task_published'] = events_by_type['task_published'][-1].timestamp  # –ü–æ—Å–ª–µ–¥–Ω—è—è –ø—É–±–ª–∏–∫–∞—Ü–∏—è
        
        if 'task_received' in events_by_type:
            timeline['task_received'] = events_by_type['task_received'][-1].timestamp
        
        if 'parsing_started' in events_by_type:
            timeline['parsing_started'] = events_by_type['parsing_started'][-1].timestamp
        
        if 'parsing_completed' in events_by_type:
            timeline['parsing_completed'] = events_by_type['parsing_completed'][-1].timestamp
        
        # –í—ã—á–∏—Å–ª—è–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
        intervals = {}
        timeline_keys = list(timeline.keys())
        
        for i in range(len(timeline_keys) - 1):
            current_key = timeline_keys[i]
            next_key = timeline_keys[i + 1]
            interval = timeline[next_key] - timeline[current_key]
            intervals[f"{current_key}_to_{next_key}"] = interval.total_seconds()
        
        return {
            "task_id": task_id,
            "timeline": timeline,
            "intervals": intervals,
            "events_count": len(task_events),
            "total_time": (max(timeline.values()) - min(timeline.values())).total_seconds() if timeline else 0
        }
    
    def analyze_recent_activity(self, hours: int = 24) -> Dict[str, any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —á–∞—Å–æ–≤."""
        cutoff_time = datetime.now() - timedelta(hours=hours)
        recent_events = [e for e in self.events if e.timestamp >= cutoff_time]
        
        if not recent_events:
            return {"message": f"–°–æ–±—ã—Ç–∏–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ {hours} —á–∞—Å–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"}
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∑–∞–¥–∞—á–∞–º
        tasks = {}
        for event in recent_events:
            if event.task_id:
                if event.task_id not in tasks:
                    tasks[event.task_id] = []
                tasks[event.task_id].append(event)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é –∑–∞–¥–∞—á—É
        results = {}
        for task_id, task_events in tasks.items():
            results[task_id] = self.analyze_task_timing(task_id)
        
        return {
            "period_hours": hours,
            "total_events": len(recent_events),
            "tasks_analyzed": len(tasks),
            "tasks": results
        }
    
    def print_task_analysis(self, task_id: int):
        """–í—ã–≤–æ–¥–∏—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –∑–∞–¥–∞—á–∏."""
        analysis = self.analyze_task_timing(task_id)
        
        if "error" in analysis:
            print(f"‚ùå {analysis['error']}")
            return
        
        print(f"\nüìä –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –¥–ª—è –∑–∞–¥–∞—á–∏ #{task_id}")
        print("=" * 60)
        
        timeline = analysis['timeline']
        intervals = analysis['intervals']
        
        print(f"üìÖ –í—Ä–µ–º–µ–Ω–Ω–∞—è —à–∫–∞–ª–∞:")
        for stage, timestamp in timeline.items():
            print(f"   {stage:20} | {timestamp.strftime('%H:%M:%S.%f')[:-3]}")
        
        print(f"\n‚è±Ô∏è –ò–Ω—Ç–µ—Ä–≤–∞–ª—ã –º–µ–∂–¥—É —ç—Ç–∞–ø–∞–º–∏:")
        for interval_name, seconds in intervals.items():
            stages = interval_name.replace('_to_', ' ‚Üí ')
            print(f"   {stages:40} | {seconds:8.3f} —Å–µ–∫")
        
        print(f"\nüìà –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   –í—Å–µ–≥–æ —Å–æ–±—ã—Ç–∏–π: {analysis['events_count']}")
        print(f"   –û–±—â–µ–µ –≤—Ä–µ–º—è:   {analysis['total_time']:.3f} —Å–µ–∫")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–∞–º—ã–µ –º–µ–¥–ª–µ–Ω–Ω—ã–µ —ç—Ç–∞–ø—ã
        if intervals:
            slowest = max(intervals.items(), key=lambda x: x[1])
            print(f"   –°–∞–º—ã–π –º–µ–¥–ª–µ–Ω–Ω—ã–π —ç—Ç–∞–ø: {slowest[0].replace('_to_', ' ‚Üí ')} ({slowest[1]:.3f} —Å–µ–∫)")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    logs_dir = Path(__file__).parent.parent / "logs"
    
    if not logs_dir.exists():
        print(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ª–æ–≥–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {logs_dir}")
        return
    
    analyzer = TimingAnalyzer(logs_dir)
    
    # –ü–∞—Ä—Å–∏–º –ª–æ–≥–∏ –∑–∞ —Å–µ–≥–æ–¥–Ω—è
    today = datetime.now().strftime('%Y-%m-%d')
    print(f"üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ª–æ–≥–∏ –∑–∞ {today}...")
    analyzer.parse_logs(date_filter=today)
    
    if len(sys.argv) > 1:
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –∑–∞–¥–∞—á—É
        try:
            task_id = int(sys.argv[1])
            analyzer.print_task_analysis(task_id)
        except ValueError:
            print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π ID –∑–∞–¥–∞—á–∏. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: python analyze_timing.py <task_id>")
    else:
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–±—â—É—é –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        print("\nüìä –ê–Ω–∞–ª–∏–∑ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞:")
        recent = analyzer.analyze_recent_activity(24)
        
        if "message" in recent:
            print(f"‚ÑπÔ∏è {recent['message']}")
        else:
            print(f"üìà –í—Å–µ–≥–æ —Å–æ–±—ã—Ç–∏–π: {recent['total_events']}")
            print(f"üìã –ó–∞–¥–∞—á –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {recent['tasks_analyzed']}")
            
            for task_id, task_analysis in recent['tasks'].items():
                if "error" not in task_analysis:
                    print(f"\nüéØ –ó–∞–¥–∞—á–∞ #{task_id}:")
                    print(f"   –û–±—â–µ–µ –≤—Ä–µ–º—è: {task_analysis['total_time']:.3f} —Å–µ–∫")
                    print(f"   –°–æ–±—ã—Ç–∏–π: {task_analysis['events_count']}")
        
        print(f"\nüí° –î–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:")
        print(f"   python analyze_timing.py <task_id>")

if __name__ == "__main__":
    main()
